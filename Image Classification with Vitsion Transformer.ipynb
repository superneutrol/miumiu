{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "\n",
    "SEED = 42 \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 100 \n",
    "INPUT_SHAPE = ( 32,32,3)\n",
    "\n",
    "(x_train , y_train) , (x_test , y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f'x_train.shape : {x_train.shape} - y_train.shape : {y_train.shape}')\n",
    "print(f'x_test.shape: {x_test.shape} - y_test.shape : {y_test.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "BUFFER_SIZE = 512 \n",
    "BATCH_SIZE = 256 \n",
    "\n",
    "# AUGMENTATION \n",
    "IMAGE_SIZE = 72 \n",
    "PATCH_SIZE = 6 \n",
    "NUM_PATCHES = (IMAGE_SIZE //  PATCH_SIZE) **2\n",
    "\n",
    "#OPTIMIZER \n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# TRAINING \n",
    "EPOCHS = 50\n",
    "# ACHITECTURE \n",
    "LAYER_NORM_EPS = 1e-6\n",
    "TRANSFOERMERS_LAYERS = 8\n",
    "PROJECTION_DIM = 64\n",
    "NUM_HEADS = 4 \n",
    "TRANSFORMER_UNITS = [\n",
    "    PROJECTION_DIM * 2 ,\n",
    "    PROJECTION_DIM,\n",
    "]\n",
    "MLP_HEAD_UNITS = [2048 , 1024]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2 , width_factor=0.2),\n",
    "    ],\n",
    "    name = 'data_augmentation',\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Shifted Patch Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedPatchTokenization(layers.Layer):\n",
    "    def __init__(\n",
    "            self, \n",
    "            image_size = IMAGE_SIZE,\n",
    "            patch_size=PATCH_SIZE,\n",
    "        num_patches=NUM_PATCHES,\n",
    "        projection_dim=PROJECTION_DIM,\n",
    "        vanilla=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vanilla = vanilla  # Flag to swtich to vanilla patch extractor\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.half_patch = patch_size // 2\n",
    "        self.flatten_patches = layers.Reshape((num_patches, -1))\n",
    "        self.projection = layers.Dense(units=projection_dim )\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
    "\n",
    "    def crop_shift_pad(self, images, mode):\n",
    "        # Build the diagonally shifted images\n",
    "        if mode == \"left-up\":\n",
    "            crop_height = self.half_patch\n",
    "            crop_width = self.half_patch\n",
    "            shift_height = 0\n",
    "            shift_width = 0\n",
    "        elif mode == \"left-down\":\n",
    "            crop_height = 0\n",
    "            crop_width = self.half_patch\n",
    "            shift_height = self.half_patch\n",
    "            shift_width = 0\n",
    "        elif mode == \"right-up\":\n",
    "            crop_height = self.half_patch\n",
    "            crop_width = 0\n",
    "            shift_height = 0\n",
    "            shift_width = self.half_patch\n",
    "        else:\n",
    "            crop_height = 0\n",
    "            crop_width = 0\n",
    "            shift_height = self.half_patch\n",
    "            shift_width = self.half_patch\n",
    "\n",
    "        # Crop the shifted images and pad them\n",
    "        crop = tf.image.crop_to_bounding_box(\n",
    "            images,\n",
    "            offset_height=crop_height,\n",
    "            offset_width=crop_width,\n",
    "            target_height=self.image_size - self.half_patch,\n",
    "            target_width=self.image_size - self.half_patch,\n",
    "        )\n",
    "        shift_pad = tf.image.pad_to_bounding_box(\n",
    "            crop,\n",
    "            offset_height=shift_height,\n",
    "            offset_width=shift_width,\n",
    "            target_height=self.image_size,\n",
    "            target_width=self.image_size,\n",
    "        )\n",
    "        return shift_pad\n",
    "    def call(self, images):\n",
    "        if not self.vanilla:\n",
    "            # Concat the shifted images with the original image \n",
    "            images = tf.concat(\n",
    "                [\n",
    "                    images , \n",
    "                    self.crop_shift_pad(images, mode=\"left-up\"),\n",
    "                    self.crop_shift_pad(images, mode=\"left-down\"),\n",
    "                    self.crop_shift_pad(images, mode=\"right-up\"),\n",
    "                    self.crop_shift_pad(images, mode=\"right-down\"),\n",
    "                ]\n",
    "            )\n",
    "        # Patchify the images and flatten it\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images , \n",
    "            sizes = [1, self.patch_size, self.patch_size , 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        flat_patches = self.flatten_patches(patches)\n",
    "        if not self.vanilla:\n",
    "            # Layer normalize the flat patches and linearly project it\n",
    "            tokens = self.layer_norm(flat_patches)\n",
    "            tokens = self.projection(tokens)\n",
    "        else:\n",
    "            # Linearly project the flat patches\n",
    "            tokens = self.projection(flat_patches)\n",
    "        return (tokens, patches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image from the training dataset\n",
    "# and resize the image\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    ")\n",
    "\n",
    "# Vanilla patch maker: This takes an image and divides into\n",
    "# patches as in the original ViT paper\n",
    "(token, patch) = ShiftedPatchTokenization(vanilla=True)(resized_image / 255.0)\n",
    "(token, patch) = (token[0], patch[0])\n",
    "n = patch.shape[0]\n",
    "count = 1\n",
    "plt.figure(figsize=(4, 4))\n",
    "for row in range(n):\n",
    "    for col in range(n):\n",
    "        plt.subplot(n, n, count)\n",
    "        count = count + 1\n",
    "        image = tf.reshape(patch[row][col], (PATCH_SIZE, PATCH_SIZE, 3))\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Shifted Patch Tokenization: This layer takes the image, shifts it\n",
    "# diagonally and then extracts patches from the concatinated images\n",
    "(token, patch) = ShiftedPatchTokenization(vanilla=False)(resized_image / 255.0)\n",
    "(token, patch) = (token[0], patch[0])\n",
    "n = patch.shape[0]\n",
    "shifted_images = [\"ORIGINAL\", \"LEFT-UP\", \"LEFT-DOWN\", \"RIGHT-UP\", \"RIGHT-DOWN\"]\n",
    "for index, name in enumerate(shifted_images):\n",
    "    print(name)\n",
    "    count = 1\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    for row in range(n):\n",
    "        for col in range(n):\n",
    "            plt.subplot(n, n, count)\n",
    "            count = count + 1\n",
    "            image = tf.reshape(patch[row][col], (PATCH_SIZE, PATCH_SIZE, 5 * 3))\n",
    "            plt.imshow(image[..., 3 * index : 3 * index + 3])\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the patch encoding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(\n",
    "            self, num_patches=NUM_PATCHES,\n",
    "            projection_dim = PROJECTION_DIM, \n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches , output_dim=projection_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0 , limit=self.num_patches, delta=1)\n",
    "\n",
    "    def call(self, encoded_patches):\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_patches = encoded_patches + encoded_positions\n",
    "        return encoded_patches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Locality Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionLSA(tf.keras.layers.MultiHeadAttention):\n",
    "    def __init__(self, **kwargs):\n",
    "        super() .__init__(**kwargs)\n",
    "        # The trainable temperature term. The initial value is\n",
    "        # the square root of the key dimension.\n",
    "        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True)\n",
    "\n",
    "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
    "        query = tf.multiply(query, 1.0 /self.tau)\n",
    "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
    "        attention_scores = self._masked_softmax(attention_scores , attention_mask)\n",
    "        attention_scores_dropout = self._dropout_layer(\n",
    "            attention_scores, training=training \n",
    "        )\n",
    "        attention_output = tf.einsum(\n",
    "            self._combine_equation, attention_scores_dropout, value\n",
    "        )\n",
    "        return attention_output, attention_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Build the diagonal attention mask\n",
    "diag_attn_mask = 1 - tf.eye(NUM_PATCHES)\n",
    "diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(vanilla=False):\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE)\n",
    "    # augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # create patches \n",
    "    (tokens, _) = ShiftedPatchTokenization(vanilla=vanilla)(augmented)\n",
    "    # Encoder patches \n",
    "    encoded_patches = PatchEncoder()(tokens)\n",
    "\n",
    "    # Create multiple layers of the trainssformer Block \n",
    "    for _ in range(TRANSFOERMERS_LAYERS):\n",
    "        # LAYER normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer \n",
    "        if not vanilla :\n",
    "            attention_output = MultiheadAttentionLSA(\n",
    "                num_heads = NUM_HEADS, key_dim = PROJECTION_DIM, dropout=0.1\n",
    "            )(x1, x1, attention_mask=diag_attn_mask)\n",
    "        else:\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "                num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
    "            )(x1 , x1)\n",
    "        # Skip connection 1 \n",
    "        x2 = layers.Add()([attention_output , encoded_patches])\n",
    "        # Layer normalization 2 \n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP \n",
    "        x3 = mlp(x3 , hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
    "        # Skip connection 2 \n",
    "        encoded_patches = layers.Add()([x2,x3])\n",
    "    \n",
    "     # Create a [batch_size, projection_dim] tensor.\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=MLP_HEAD_UNITS, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(NUM_CLASSES)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile, train, and evaluate the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code is taken from:\n",
    "# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.\n",
    "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.pi = tf.constant(np.pi)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if self.total_steps < self.warmup_steps:\n",
    "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
    "\n",
    "        cos_annealed_lr = tf.cos(\n",
    "            self.pi\n",
    "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
    "            / float(self.total_steps - self.warmup_steps)\n",
    "        )\n",
    "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
    "\n",
    "        if self.warmup_steps > 0:\n",
    "            if self.learning_rate_base < self.warmup_learning_rate:\n",
    "                raise ValueError(\n",
    "                    \"Learning_rate_base must be larger or equal to \"\n",
    "                    \"warmup_learning_rate.\"\n",
    "                )\n",
    "            slope = (\n",
    "                self.learning_rate_base - self.warmup_learning_rate\n",
    "            ) / self.warmup_steps\n",
    "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
    "            learning_rate = tf.where(\n",
    "                step < self.warmup_steps, warmup_rate, learning_rate\n",
    "            )\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
    "        )\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "    total_steps = int((len(x_train) / BATCH_SIZE) * EPOCHS)\n",
    "    warmup_epoch_percentage = 0.10\n",
    "    warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "    scheduled_lrs = WarmUpCosine(\n",
    "        learning_rate_base=LEARNING_RATE,\n",
    "        total_steps=total_steps,\n",
    "        warmup_learning_rate=0.0,\n",
    "        warmup_steps=warmup_steps,\n",
    "    )\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "    )\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# Run experiments with the vanilla ViT\n",
    "vit = create_vit_classifier(vanilla=True)\n",
    "history = run_experiment(vit)\n",
    "\n",
    "# Run experiments with the Shifted Patch Tokenization and\n",
    "# Locality Self Attention modified ViT\n",
    "vit_sl = create_vit_classifier(vanilla=False)\n",
    "history = run_experiment(vit_sl)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
