{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39ce23f",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7512502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c8cec",
   "metadata": {},
   "source": [
    "### Dowload and prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000# xem xét 20000 từ đầu tiên /  Only consider the top 20k words \n",
    "num_tokens_per_example = 200  # chỉ xem xét 200 từ đầu tiên của mỗi đánh giá\n",
    "# Only consider the first 200 words of each movie review \n",
    "(x_train , y_train) , (x_val , y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_val) , 'Training sequences')\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "# biến đổi đầu vào thành một chuỗi tuần tự\n",
    "x_train = keras.utils.pad_sequences(\n",
    "    x_train , maxlen=num_tokens_per_example\n",
    ")\n",
    "\n",
    "x_val = keras.utils.pad_sequences(x_val , maxlen=num_tokens_per_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06269c45",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32 # embedding size for each token\n",
    "num_heads = 2  # number of attention heads \n",
    "ff_dim = 32 # hidden layers size in feedforward network \n",
    "num_experts = 10 # number expert used in the Switch Trasformer\n",
    "batch_size = 50 \n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.25\n",
    "num_epochs = 3\n",
    "num_tokens_per_batch = (\n",
    "    batch_size * num_tokens_per_example\n",
    ") # total number of tokes per patch  / tổng số tokens của mỗi patch \n",
    "print(f'Number of tokens per patch : {num_tokens_per_batch}') # 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4251f22b",
   "metadata": {},
   "source": [
    "### Implement token & position embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ec180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen , vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        # ở vector nhúng embeding nhận đầu vào là kích thước tập từ vựng\n",
    "        # trả về số chiều nhúng \n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size , output_dim=embed_dim\n",
    "        )\n",
    "        # vector nhúng vị trí nhận vào kích thước độ dài mỗi vector = maxlen \n",
    "        # trả về số chiều nhúng \n",
    "        self.pos_emb = layers.Embedding(\n",
    "            input_dim = maxlen ,output_dim = embed_dim\n",
    "        )\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0 , limit=maxlen, delta=0)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494a703",
   "metadata": {},
   "source": [
    "### Implement the Feedforward network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e48d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedforward_network(ff_dim , name=None):\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(ff_dim , activation='relu'), \n",
    "            layers.Dense(ff_dim),\n",
    "        ], \n",
    "        name = name ,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab2613",
   "metadata": {},
   "source": [
    "### Implement the load_balanced loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6277958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balanced_loss(router_probs , expert_mask):\n",
    "    # loss = alpha.N . sum(1-> N). f(i) .p(i)\n",
    "    # f(i) là tỷ lệ mã thông báo được gửi đến chuyên gia i \n",
    "    # p(i)là xác xuất bộ định tuyến được phân bổ cho chuyên gia i\n",
    "    # hàm mất mát cân bằng tải nhận đầu vào là\n",
    "    # router_probs [token_per_batch , num_expert] là xác xuất được chỉ định \n",
    "    # cho mỗi chuyên gia trên mã thông báo\n",
    "    # expert_mask [tokens_per_batch, num_experts] chứa chuyên gia có xác xuất \n",
    "    # bộ định tuyến cao nhát dạng one hot \n",
    "    num_experts = tf.shape(expert_mask)[-1]\n",
    "    # nhận phần nhỏ mã thông báo được gửi đến mỗi chuyên gia \n",
    "    # xác xuất là 1 vector với độ dài = num chuyên giá có tổng = 1\n",
    "    # (fi)fi =1/T .sum (x E B) 1{argmax p(x) = i}\n",
    "    density = tf.reduce_mean(expert_mask , axis=0)\n",
    "    # nhận một phần khối lượng xác xuất được chỉ định cho từng chuyên gia\n",
    "    # từ bộ định tuyến trên tất cả mã thông báo  xác xuất là 1 vector \n",
    "    # với độ dài = num chuyên giá có tổng = 1\n",
    "    #(pi)\n",
    "    density_probs = tf.reduce_mean(router_probs , axis=0)\n",
    "    # muốn cả 2 vectors có phân bổ thống nhất 1 / num_expertsm trên tất cả \n",
    "    # num_expert phần tử . Hai vector sẽ được đẩy về phía phân bổ thống nhất \n",
    "    # khi tích vô hướng được thu nhỏ\n",
    "    loss = tf.reduce_mean(density * density_probs) * tf.cast(\n",
    "            (num_experts **2), tf.dtypes.float32,\n",
    "    )\n",
    "    return loss \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e59fe4",
   "metadata": {},
   "source": [
    "### Implement the router as a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde28b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính toán phân bổ cho các chuyên gia và năng lực của chuyên gia \n",
    "class Router(layers.Layer):\n",
    "    def __init__(self, num_experts , expert_capacity):\n",
    "        self.num_experts = num_experts \n",
    "        self.route = layers.Dense(units=num_experts)\n",
    "        self.expert_capacity = expert_capacity\n",
    "        super().__init__()\n",
    "    def call(self, inputs , training=False):\n",
    "        # input shape = [tokens_per_patch , embed_dim]\n",
    "        # router_logits shape = [tokens_per_patch , num_experst]\n",
    "        # khởi tạo router logits = route(inputs)\n",
    "        router_logits = self.route(inputs)\n",
    "        if training:\n",
    "            # Thêm nhiễu để khám phá giữa các chuyên gia \n",
    "            # một ma trận bằng chính nó với min = 0.9 max = 1.1\n",
    "            router_logits += tf.random.uniform(\n",
    "                shape=router_logits.shape , minval=0.9 , maxval=1.1\n",
    "            )\n",
    "        # tính xác xuất của mỗi mã thông báo mà nó được gửi tới các chuyên gia \n",
    "        # là xác xuất cao nhất trên chuyên gia qua softmax\n",
    "        router_probs = keras.activations.softmax(router_logits, axis=-1)\n",
    "        # sử dụng hàm top k để lấy ra expert có xác xuất cao nhất cho mỗi token \n",
    "        # Kết quả trả về 2 ma trận shape [token_per_patch, 1] , \n",
    "        # expert_gate chứa xác xuất cao nhất cho mã thông báo thứ i \n",
    "        # expert index là chỉ số của expert tương ứng \n",
    "        expert_gate , expert_index = tf.math.top_k(router_probs, k=1)\n",
    "        # khởi tạo ma trận expert_mask shape [token_per_patch, num_experts]\n",
    "        # trong expert[i, j] bằng 1 nếu token thứ i được gửi đến chuyên gia j \n",
    "        # và bằng 0 nếu ngược lại \n",
    "        expert_mask = tf.one_hot(expert_index , depth=self.num_experts)\n",
    "        # tính toán hàm mất mát cân bằng tải \n",
    "        aux_loss= load_balanced_loss(router_probs, expert_mask)\n",
    "        # Tính toán vị trí chuyên gia shape [ token_per_patch , num_experts]\n",
    "        # position_un_expert là vị trí token thứ i trong hàng đợi j \n",
    "        # được tính bằng cách cộng dồn tổng giá trị theo chiều ngang \n",
    "        position_in_expert = tf.cast(\n",
    "            tf.math.cumsum(expert_mask, axis=0) * expert_mask , tf.dtypes.int32\n",
    "        )\n",
    "        # giữ lại các mã thông báo phù hợp với năng lực của chuyên gia \n",
    "        # kiểm tra xem vị trí của mỗi token(position_in_expert) có nhỏ hơn expert_capacity không \n",
    "        # nếu có đoạn mã sẽ giữ nguyên giá trị trong expert_mask nếu ko giá trị \n",
    "        # trong expert_mask được gán  = 0\n",
    "        # chỉ những token nhỏ hơn expert_mask mới được gửi đến expert , lớn hơn thì bỏ\n",
    "        expert_mask *= tf.cast(\n",
    "            tf.math.less(\n",
    "                    tf.cast(position_in_expert , tf.dtypes.int32) , self.expert_capacity\n",
    "            ),\n",
    "            tf.dtypes.float32,\n",
    "        )\n",
    "        # tính toán expert_mask_flat là một ma trận có kích thước [token_per_patch]\n",
    "        # trong đó phần tử expert_mask_flat[i] đại diện cho tổng số lượng các chuyên gia mà token thứ i được gửi đến \n",
    "        # vd tokens 1 sẽ được gửi đén  n chyên gia \n",
    "        # đoạn mã phục vụ để loại bỏ những token khônng được gửi đến expert nào \n",
    "        expert_mask_flat = tf.reduce_mean(expert_mask ,axis=-1)\n",
    "        expert_gate *= expert_mask_flat \n",
    "        # tạo một tensor kết hợp shape [token_per_patch , num_expert , expert_capacity]\n",
    "        # combined_tensor[i,j ,k] băng = 1 nếu token thứ i được gửi đến expert thứ j cps vị trí thứu k \n",
    "        # trong hàng đợi của expert mask đó \n",
    "        # sử dụng tf.sqeeze để loại bỏ các chiều có kích thước bằng 1 trong kích thước của 1 tensor \n",
    "        combined_tensor = tf.expand_dims(\n",
    "            expert_gate * expert_mask_flat * \n",
    "            tf.squeeze(tf.one_hot(expert_index , depth=self.num_experts) , 1),\n",
    "            -1\n",
    "        )* tf.squeeze(tf.one_hot(position_in_expert, depth=self.expert_capacity),1)\n",
    "        # xây dựng dispatch tensor là một ma trận nhị phân \n",
    "        # shape [token_per_patch , num_experts , expert_capacity] \n",
    "        #  = 1 nếu mã thông báo gửi đến chuyên gia tương ứng \n",
    "        dispatch_tensor = tf.cast(combined_tensor, tf.dtypes.float32)\n",
    "        \n",
    "        return dispatch_tensor, combined_tensor \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c5ad0",
   "metadata": {},
   "source": [
    "### Implement a Swicth layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b336052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Switch(layers.Layer):\n",
    "    def __init__(self,num_experts, embed_dim , num_tokens_per_batch, capacity_factor=1):\n",
    "        self.num_exprets = num_experts \n",
    "        self.num_tokens_per_batch = num_tokens_per_batch\n",
    "        self.embed_dim = embed_dim \n",
    "        self.experts = [\n",
    "            create_feedforward_network(embed_dim) for _ in range(num_experts)\n",
    "        ]\n",
    "        self.expert_capacity = num_tokens_per_batch // num_experts \n",
    "        self.route = Router(num_experts, self.expert_capacity)\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # inputs shape ;[num_tokens_per_patch]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        num_tokens_per_xample = tf.shape(inputs)[1]\n",
    "        \n",
    "        # input shape : [num_tokens_per_patch , embed_dim]\n",
    "        inputs = tf.reshape(inputs , [self.num_tokens_per_batch , self.embed_dim])\n",
    "        # dispatch_tensor shape : [tokens_per_patch, num_experts, expert_capacity]\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        dispatch_tensor, combined_tensor = self.route(inputs)\n",
    "        # thiết lập đầu vào cho chuyên gia \n",
    "        # expert_input shape : [num_epxerts , expert_capacity , embed_dim]\n",
    "        expert_inputs = tf.einsum(\"ab , acd->cdb\" , inputs , dispatch_tensor)\n",
    "        expert_inputs = tf.reshape(\n",
    "            expert_inputs , [num_experts, self.expert_capacity, self.embed_dim]\n",
    "        )\n",
    "        # thiết lập danh sách tensor gửi đến chuyên gia \n",
    "        # gửi các token đến các chuyên gia bằng cách tách expert_input thành 1 danh\n",
    "        # sách các tensor theo chiều ngang shape [expert_capacity , embed_dim]\n",
    "        expert_input_list = tf.unstack(expert_inputs, axis=0)\n",
    "        expert_output_list = [ \n",
    "            # chuyên gia tính toán đầu vào từ danh sách expert_input_list theo vị trí idx các mã thông báo \n",
    "            self.experts[idx](expert_input)\n",
    "            for idx , expert_input in enumerate(expert_input_list)\n",
    "        ]\n",
    "        # thiết lập đầu ra của các chuyên gia \n",
    "        # nối các tensor theo danh sách ở trên theo chiều dọc \n",
    "        # shape mới  : [expert_capacity , num_expert , embed_dim]\n",
    "        # chứa biểu diễn mới của tokens sau khi qua expert\n",
    "        expert_outputs = tf.stack(expert_output_list , axis=1)\n",
    "        # đầu ra kết hợp expert_output_combined shape :[token_per_patch ,embed_dim]\n",
    "        expert_outputs_combined = tf.einsum(\n",
    "                \"abc,xba->xc\", expert_outputs , combined_tensor # => [token_per_patch, embed_dim]\n",
    "        )\n",
    "        # output _shape [batch_size , num_token_per_example , embed_dim]\n",
    "        # reshape output \n",
    "        outputs = tf.reshape (\n",
    "            expert_outputs_combined , [batch_size , num_tokens_per_example , self.embed_dim]\n",
    "        )\n",
    "        \n",
    "        return outputs \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e3914",
   "metadata": {},
   "source": [
    "### Implement a Transfoemer bolck layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim , num_heads , ffn ,dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads\n",
    "        self.ffn = ffn\n",
    "        self.attn = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads , key_dim = embed_dim\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_outputs = self.attn(inputs, inputs)\n",
    "        att_outputs = self.dropout1(attn_outputs, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_outputs)\n",
    "        ffn_outputs = self.ffn(out1)\n",
    "        ffn_outputs = self.dropout2(ffn_outputs, training=training)\n",
    "        return self.layernorm2(out1 + ffn_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf113760",
   "metadata": {},
   "source": [
    "### Implement the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "    switch = Switch(num_experts , embed_dim , num_tokens_per_batch)\n",
    "    transformer_block = TransformerBlock(ff_dim , num_heads, switch)\n",
    "    \n",
    "    inputs = layers.Input((num_tokens_per_example ,))\n",
    "    # thưucj hiện lớp nhúng từ và vị trí \n",
    "    embedding_layers = TokenAndPositionEmbedding(\n",
    "        num_tokens_per_example , vocab_size , embed_dim\n",
    "    )\n",
    "    # xây dựng các lớp đầu đủ thành mô hình \n",
    "    x = embedding_layers(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(ff_dim , activation='relu')(X)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(2 , activation='softmax')(x)\n",
    "    \n",
    "    outputs = x\n",
    "    classifier = keras.Model(inputs=inputs, outputs = outputs)\n",
    "    return classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efc42e",
   "metadata": {},
   "source": [
    "### Train and evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(classifier):\n",
    "    classifier.compile(\n",
    "        optimizer= keras.optimizers.Adam(learning_rate),\n",
    "        loss = \"sparse_categorical_crossentropy\",\n",
    "        metrics = ['accuracy'],\n",
    "    )\n",
    "    history = classifier.fit(\n",
    "        x_train , y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = 3 , \n",
    "        validation_data = (x_val ,y_val)\n",
    "    )\n",
    "    return history \n",
    "\n",
    "classifier = create_classifier()\n",
    "run_experiment(classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
