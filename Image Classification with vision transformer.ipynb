{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thư viện  pandas , numpy , keras , tensorflow \n",
    "from tensorflow import keras\n",
    "from keras import layers \n",
    "from keras.layers import Dense \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn bị dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dong2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100 \n",
    "input_shape = ( 32 , 32 ,3)\n",
    "(x_train , y_train) ,(x_test ,y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Định cấu Hình Siêu tham số \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 \n",
    "weight_decay = 0.0001\n",
    "batch_size = 256 \n",
    "num_epochs = 100 \n",
    "image_size = 72 \n",
    "patch_size = 6 \n",
    "num_patches = (image_size // patch_size) **2\n",
    "projection_dim  = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2 ,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048 , 1024]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng tăng cường dữ liệu hình ảnh cho mô hình vision transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        # Thực hiện 1 lớp bình thường hóa cho hình ảnh\n",
    "        layers.Normalization(),\n",
    "        # Đặt lại hình ảnh với shape [image_size , image_size]\n",
    "        layers.Resizing(image_size, image_size), \n",
    "        # ật ảnh với RandomFlip\n",
    "        layers.RandomFlip('honrizontal'),\n",
    "        # Xoay hình ảnh \n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        # phóng to hình ảnh \n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2 , width_factor=0.2\n",
    "        ),\n",
    "    ], \n",
    "    # Thiết lập name = data_augment ( tăng cường dữ liệu hình ảnh)\n",
    "    name = 'data_augmentation',\n",
    ")\n",
    "# Biến đổi thích nghi đầu vào cho phù hợp với quy chuẩn \n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện lớp đa đầu Mlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng lớp MLP tương tự như 1 lớp kết nối đầy đủ fully connected \n",
    "# nhận đầu vào là số chiều nhúng và tỷ lệ rời bỏ \n",
    "def mlp(x , hidden_units , dropout_rate):\n",
    "    # Duyêth qua danh sách chứa tập hợp số lượng đơn vị units \n",
    "    for units in hidden_units:\n",
    "        # Thực hiện đưa các units vào mạng Dense cho việc nhúng sâu \n",
    "        x = layers.Dense(units , activation=tf.nn.gelu)(x) # sử dụng hàm kích hoạt gelu \n",
    "        # Thêm 1 lớp rời bỏ với tỷ lệ đặt bằng tham số dropout_rate\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    # Trả về bộ tham số vector X sau khi áp dụng lớp rời bỏ \n",
    "    return x "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành thực hiện khởi tạo bản vá như 1 lớp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng 1 lớp phương thức sử dụng cho việc trích xuất các bản vá từ hình ảnh\n",
    "# ban đầu tra về các bản với với kích thước patch_size , patch_size , batch\n",
    "class Patches(layers.Layer):\n",
    "    # Thiết lập phương thức khởi tạo nhận tha số đầu vào là patch_size \n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size \n",
    "        # Xây dựng phương thức call thực hiện cho công việc trích xuất bản vá\n",
    "    def call(self, images):\n",
    "        # Lấy ra kích thước lô từ nguồn đầu vào \n",
    "        batch_size = tf.shape(images)[0]\n",
    "        # sử dụng tf.image.extract_patches để tríc xuất và đặt quy chuẩn cho các  bản vá \n",
    "        patches = tf.image.extract_patches(\n",
    "            # Nhận nguồn là ảnh đầu vào \n",
    "            images = images , \n",
    "            sizes = [ 1 , self.patch_size, patch_size, 1],\n",
    "            strides = [1 , self.patch_size , self.patch_size, 1],\n",
    "            rates = [1 , 1 , 1 , 1],\n",
    "            padding = 'VALID',\n",
    "        )\n",
    "        # Lấy ra số chiều nhúng \n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches , [batch_size , -1 , patch_dims])\n",
    "        return patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(4 , 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "\n",
    "plt.imshow(image.astype('uint8'))\n",
    "plt.axis('off')\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]) , size =(image_size ,image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4 ,4))\n",
    "for i , patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n , n , i+1)\n",
    "    patch_img = tf.reshape(patch , (patch_size , patch_size ,3))\n",
    "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng lớp mã hóa bản vá lỗi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.layer):\n",
    "    def __init__(self, num_patches ,projection_dim):\n",
    "        self.num_patches = num_patches \n",
    "        self.proj = layers.Dense(projection_dim)\n",
    "        self.pos_embed = layers.Embedding(\n",
    "            input_dim=num_patches , output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start = 0 , limit=self.num_patches , delta=1)\n",
    "        encode = self.proj(patch) + self.pos_embed(positions)\n",
    "        return encode "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng mô hình vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # create patches \n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    # encode patches \n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # create multi layers of the transformer block \n",
    "    for _ in range (transformer_layers):\n",
    "        # layers normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        # create multihead attention layers \n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_classes, key_dim = projection_dim , dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # add skip connection 1\n",
    "        x2 = layers.Add()([attention_output , encoded_patches])\n",
    "        # add layer normal 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # add mlp \n",
    "        x3 = mlp(x3 ,hidden_units=transformer_units , dropout_rate=0.1)\n",
    "        # skip connection 2\n",
    "        encoded_patches = layers.Add()([x3 , x2])\n",
    "\n",
    "    #crearte a [batch_size , projection_dim] tensor \n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "\n",
    "    # addd mlp \n",
    "    features = mlp(representation , hidden_units=mlp_head_units , dropout_rate=0.5)\n",
    "\n",
    "    # classifier output \n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    \n",
    "    # creaet the keras.modes\n",
    "    model = keras.Model(inputs=inputs , outputs=logits)\n",
    "    return model \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huấn luyện , tối ưu , và đánh giá mô hình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
