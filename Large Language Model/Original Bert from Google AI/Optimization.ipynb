{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import re \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xây dựng trình tối ưu hóa cho mô hình Bert \n",
    "def create_optimizer(loss , init_lr, num_train_steps , num_warmup_steps, use_tpu):\n",
    "    \"\"\"Creates an optimizer training op.\"\"\"\n",
    "    # Khởi tạon một biến toàn bộ đại diện cho toàn bộ bước thời gian \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # khởi tạo một giá trị là lr là một giá trị float value = lr \n",
    "    learning_rate = tf.constant(value=init_lr , shape=[] , dtype=tf.float32)\n",
    "\n",
    "    # Thực hiện các tuyến tính phân dã cho tỷ lệ học tập \n",
    "    learning_rate = tf.train.polynomial_decay(\n",
    "        learning_rate , global_step , num_train_steps , end_learning_rate =0.0,\n",
    "        power=1.0, cycle = False \n",
    "    )\n",
    "\n",
    "    # làm nóng tuyến tính .. nếu như toàn bộ các bước thời gian < số lượn bước khởi động \n",
    "    # thì tỷ lêh học tập sẽ là 'global/num_warup_steps , * init_lt ' . \n",
    "    # đầu tiên ta kiểm tra xem num_warup_steps có tồn tại hay không \n",
    "    if num_warmup_steps: \n",
    "        # gán toàn bộ các bước thời gia là một giá trị int được biểu thị bởi Global_step \n",
    "        global_steps_int = tf.cast(global_step, dtype=tf.int32 )\n",
    "        # tương tự lấy ra kết quả là số lượng bước khởi động sử dụng tf.constant để giá trị không \n",
    "        # bị thay đổi \n",
    "        warmup_steps_int = tf.constant(num_warmup_steps , dtype = tf.int32)\n",
    "\n",
    "        # từ 2 giá trị là global_steps_intvà warmup_steps_int ta chuyển 2 giá trị thành float \n",
    "        global_steps_float = tf.cast(global_steps_int, tf.float32)\n",
    "        warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\n",
    "\n",
    "        # sau đó tính tỷ lệ hoàn thành của quá trình warmup và tỷ lệ học tập trong quá trình warmup \n",
    "        warmup_percent_done = global_steps_float / warmup_steps_float\n",
    "        warmup_learning_rate = init_lr * warmup_percent_done\n",
    "\n",
    "        # Cuối cùng nó kiểm tra xem global_steps có nhỏ hơn warmup_steps_int hay không\n",
    "        # lưu kết qủa vào biến is_warmup có giá trị 1 nếu trong quá trình warup và o nếu 0 \n",
    "        is_warmup = tf.cast(global_steps_int < warmup_steps_int , tf.float32)\n",
    "\n",
    "        # và nó cũng cập nhật biến laearning_rate\n",
    "        learning_rate = (\n",
    "            (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\n",
    "\n",
    "        # Thiết lập trình tối ưu hóa \n",
    "        # sử dụng AdamWeightDecayOptimizer \n",
    "        optimizer = AdamWeightDecayOptimizer(\n",
    "                learning_rate=learning_rate,\n",
    "                weight_decay_rate=0.01,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-6,\n",
    "                exclude_from_weight_decay=[\"LayerNorm\", \"layer_norm\", \"bias\"]\n",
    "                )\n",
    "\n",
    "        # kiểm tra xem mô hình vó đang sử dụng Tpu không \n",
    "        # Nếu có thì ta sử dụng tpu để tối ưu hóa mô hình \n",
    "        if use_tpu : \n",
    "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "        \n",
    "\n",
    "        # Lấy ra danh sách các biến giá trị có thể được huấn luyên từ mô hình và gá cho \n",
    "        # Tvar\n",
    "        tvars = tf.trainable_variable()\n",
    "        # và lấy ra kết quả của gradients \n",
    "        grads = tf.gradients(loss , tvars)\n",
    "\n",
    "        # đầu tiên sử dụng hàm tf.clip_by_global_norm để cắt bớt các gradient của các biến \n",
    "        # có thể huấn luyện theo tỷ lệ tổng cac chuẩn của chúng . Mục đích là để tránh tạo các đối tượng \n",
    "        # gradient bùng nổ \n",
    "        (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\n",
    "\n",
    "\n",
    "        # sử dụng optimizer.apply_gradient để áp dụng các gradient đã cắt ớt cho các biến có thể \n",
    "        # được huấn luyện và cập nhật các giá trị global tại thời điểm đào tạo \n",
    "        train_op = optimizer.apply_gradients(\n",
    "            zip(grads, tvars), global_step=global_step)\n",
    "        \n",
    "        # nó tạo một biến mới new_global_step bằng cách cộng global_step với 1,\n",
    "        # và gán lại giá trị của global_step bằng new_global_step. Điều này là cần thiết vì lớp AdamWeightDecayOptimizer\n",
    "        # không tự động cập nhật global_step khi áp dụng các gradient\n",
    "        new_global_step = global_step + 1\n",
    "        train_op = tf.group(train_op, [global_step.assign(new_global_step)])\n",
    "        return train_op\n",
    "    \n",
    "\n",
    "class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
    "    \"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                learning_rate,\n",
    "                weight_decay_rate=0.0,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-6,\n",
    "                exclude_from_weight_decay=None,\n",
    "                name=\"AdamWeightDecayOptimizer\"):\n",
    "         \n",
    "        \"\"\"Constructs a AdamWeightDecayOptimizer.\"\"\"\n",
    "        super(AdamWeightDecayOptimizer, self).__init__(False, name)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay_rate = weight_decay_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
    "\n",
    "    # Xây dựng phương thức áp dụng gradient cho các biến có thể được huấn luyên \n",
    "    def apply_gradients(self, grads_and_vars , global_step =None , name=None):\n",
    "        \"\"\"See base class\"\"\"\n",
    "        # tạo một danh sách assigments để lưu trữ các kết quả của phép gán cập nhật tham số \n",
    "        assignments = []\n",
    "        # duyêth qua danh sách gradient của tham số và kết quả tham số \n",
    "        for (grad , param) in grads_and_vars: \n",
    "            # nếu 1 trong 2 giá trị = None thì bỏ qua cặp này \n",
    "            if grad is None or param is None: \n",
    "                continue \n",
    "\n",
    "            # sau đó lấy ra tên của tham số và gán cho param name \n",
    "            param_name = self._get_variable_name(param.name)\n",
    "\n",
    "            # khởi tạo 2 biến m và vcho mỗi tham số param , có cùng kích thước và kiểu dữ liệu với \n",
    "            # params  , m và v là các ước lượng trug bình động của gradinet (moment) và bình phương gradient \n",
    "            # của param \n",
    "\n",
    "            m = tf.get_variable(\n",
    "                name=param_name + \"/adam_m\",\n",
    "                shape=param.shape.as_list(),\n",
    "                dtype=tf.float32,\n",
    "                trainable=False,\n",
    "                initializer=tf.zeros_initializer())\n",
    "            v = tf.get_variable(\n",
    "                name=param_name + \"/adam_v\",\n",
    "                shape=param.shape.as_list(),\n",
    "                dtype=tf.float32,\n",
    "                trainable=False,\n",
    "                initializer=tf.zeros_initializer())\n",
    "\n",
    "            # cập nhật giá trị m và v theo công thức chuẩn Adam \n",
    "            # next_m = beta_1 * m + (1 - beta_1) * grad\n",
    "            # next_v = beta_2 * v + (1 - beta_2) * grad^2\n",
    "            next_m = (\n",
    "                tf.multiply(self.beta_1, m) + tf.multiply(1.0 - self.beta_1, grad))\n",
    "            next_v = (\n",
    "                tf.multiply(self.beta_2, v) + tf.multiply(1.0 - self.beta_2,\n",
    "                                                    tf.square(grad)))\n",
    "            \n",
    "            # tính toán giá trị cập nhật cho tham số params theo công thức chuẩn của Adam \n",
    "            # update  = next_m / sqrt (next_v) + epsilon \n",
    "\n",
    "            update = next_m / (tf.sqrt(next_v) + self.epsilon)\n",
    "\n",
    "            # Kiểm tra xem tham số param có cần áp dụng suy giảm trọng số (weight decay) hay không bằng\n",
    "            #  cách gọi hàm _do_use_weight_decay. Nếu có, thì cộng thêm một số lượng tỷ lệ với trọng số\n",
    "            #  param vào giá trị cập nhật. Đây là một kỹ thuật\n",
    "            #  để giảm thiểu độ phức tạp của mô hình và tránh hiện tượng quá khớp (overfitting).\n",
    "            if self._do_use_weight_decay(param_name):\n",
    "                update += self.weight_decay_rate * param\n",
    "            \n",
    "            # Nhân giá trị cập nhật với tốc độ học (learning rate), \n",
    "            # một tham số điều khiển bước nhảy của thuật toán tối ưu hóa.\n",
    "            update_with_lr = self.learning_rate * update\n",
    "            # Trừ giá trị cập nhật với tốc độ học ra khỏi tham số param để được tham số mới next_param.\n",
    "            next_param = param - update_with_lr\n",
    "\n",
    "            # Thêm các phép gán next_param, next_m và next_v vào danh sách assignments\n",
    "            assignments.extend(\n",
    "                [param.assign(next_param),\n",
    "                m.assign(next_m),\n",
    "                v.assign(next_v)])\n",
    "\n",
    "        # Trả về kết quả của hàm group trong TensorFlow, để nhóm các phép gán lại thành\n",
    "        # một đồ thị tính toán duy nhất. Tham số name là tên của đồ thị, nếu có.   \n",
    "        return tf.group(*assignments, name=name)\n",
    "\n",
    "\n",
    "    def _do_use_weight_decay(self, param_name):\n",
    "        \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
    "        if not self.weight_decay_rate:\n",
    "            return False\n",
    "        if self.exclude_from_weight_decay:\n",
    "            for r in self.exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def _get_variable_name(self, param_name):\n",
    "        \"\"\"Get the variable name from the tensor name.\"\"\"\n",
    "        m = re.match(\"^(.*):\\\\d+$\", param_name)\n",
    "        if m is not None:\n",
    "            param_name = m.group(1)\n",
    "        return param_name"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
