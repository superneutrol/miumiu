{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/ConnorJL/GPT2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os \n",
    "import time \n",
    "from multiprocessing import Pool \n",
    "\n",
    "import ftfy \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import tqdm \n",
    "\n",
    "import encoder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo một đường dẫn đến nơi chứa tệp txt \n",
    "base_dir = \"/home/connor/2/newspaper\" # Path to where your .txt files are located\n",
    "# số lượng tối đa các tệp văn bản trong mỗi tệp tfRecords \n",
    "files_per = 175000\n",
    "# và một chuỗi là tên của tệp tf.Records được tạo ra các tệp này có dạng \n",
    "# name_i.tfrecords với i là số thứ tự của tệp \n",
    "name = \"openwebtext-newspaper\"\n",
    "# Một đường dẫn thư mục lưu trữ thư mục tfrecords đầu ra \n",
    "output_dir = \"/home/connor/out\"\n",
    "# Một đường dẫn thư mục lưu các tập nhật ký logs. là các tệp văn bản chứa các thông tin \n",
    "# về quá trình chạy đoạn mã vd : như thời gian bắt đầu, kết thúc, số lượng tệp được xử lý, lỗi nếu có, v.v.\n",
    "log_dir = \"logs\"\n",
    "# file một danh sahs chưa các đường dẫn đến tất cả các tệp văn bản trong thư mục base_dir \n",
    "# và các thư mục con của nó . Sử dụng hàm global.global để trả về 1 danh sách các tệp \n",
    "# có đường dẫn với định dạng txt được tìm kiếm trong base_dir và nối các đường dẫn 1 cahs an toàn \n",
    "files = glob.glob(os.path.join(base_dir,\"**/*.txt\"))\n",
    "\n",
    "# số lượng quy trình mã hóa sẽ chạy \n",
    "processes = 64 \n",
    "# đường dẫn cho thư mục mã hóa \n",
    "encoder_path = \"gs://openwebtext/stuff/encoder\" # Path to encoder files\n",
    "minimum_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng phương thức định dạng kiểu giá trị tham số cho quy trình xử lý \n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return  tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "# Xây dựng phương thức trả về một thuộc tinh là đối tượng tf.train.BytesList là dữ liệu \n",
    "# đươcj sử dụng trong tf.trin.Example một định dạng để lưu trữ bảng ghi nhị phân . \n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Return a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# Chia danh sách thành các phần nhận 2 tham số \n",
    "# là list là 1 danh sách các bản ghi và n là lát cắt với 175000 số mẫu \n",
    "def chunks(l, n):\n",
    "    # khởi tạo 1 dnah sách rỗng để lưu chữ các phần sau khi cắt \n",
    "    out = []\n",
    "    # duyệt qua danh sách 0 -> số lượng mẫu trong tệp TfRecords với bước nhảy n \n",
    "    for i in range (0, len(l), n):\n",
    "        # Thêm vào danh sách các phần theo thứ tự i mỗi phần sẽ có số lượng từ i đến i+ n \n",
    "        # các phần tử trong danh sách đầu vào\n",
    "        out.append(l[i: i + n])\n",
    "    # Trả về kết quả danh sách đầu ra \n",
    "        return out \n",
    "\n",
    "\n",
    "# Kiểm tra xem log_dir có phải là một đường dẫn thư mục đã tồn tại \n",
    "if not os.path.exists(log_dir):\n",
    "    # nếu không ta sử dụng os.mikdir để tạo một đường dẫn thư mục log_dir \n",
    "    # từ chuỗi đường dẫn trước đó \n",
    "    os.mikdir(log_dir)\n",
    "\n",
    "# khởi tạo một biến là enc gán nó  = kết quả của quy trình xử lý tệp tfrecord cuối cùng \n",
    "# và được lưu trữ dưới dạng đường dẫn thư mục \n",
    "enc = encoder.get_encoder(encoder_path)\n",
    "\n",
    "# gán biến file_chunks = danh sách các phần được chia từ tệp tf.record \n",
    "file_chunks = chunks(files, files_per)\n",
    "\n",
    "# In ra thông báo số lượng file và số lượng tệp trong danh sách file_chunks \n",
    "print(\"Got {} files, divided into {} chunks.\".format(str(len(files)), str(len(file_chunks))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(args):\n",
    "    # gán kết quả của i và chunk  = tham só đầu vào \n",
    "    i, chunk = args \n",
    "    # gán kết quả của s  = 1 chuỗi string \n",
    "    s = name + \"_\" + str(i) + \".tfrecords\"\n",
    "    # kiểm tra xem 1 đường dẫn được nối bởi tập nhật ký và chuỗi s hiện có đang tồn tại hay không \n",
    "    if os.path.exists(os.path.join(log_dir, s)):\n",
    "        return \n",
    "    \n",
    "    # kiểm tra xem có tồn tại một tệp với đường dẫn mong muốn không nếu có\n",
    "    # tức nó chưa hoàn thiện \n",
    "    if os.path.exists(os.path.join(output_dir, s)):\n",
    "        os.remove(os.path.join(output_dir, s))\n",
    "\n",
    "    # Khởi tạo một trường hợp biến phạm vi \n",
    "    # mục đích tạo một đối tượng write dể ghi các bản ghi vào một tệp TFRecords\n",
    "    with tf.python_io.TFRecordWriter(os.path.join(output_dir, s)) as writer: \n",
    "        good_files = 0\n",
    "        current = None\n",
    "\n",
    "        # Duyệt qua danh sách các phần mẫu trong chunk \n",
    "        # mỗi phần gồm nhiều file\n",
    "        for fn in chunk: \n",
    "            # mở tất cả các file trong mỗi phần đặt ở chế độ cho phép đọc và gán nó cho biến f \n",
    "            with tf.gfile.Opent(fn, \"r\") as f: \n",
    "                #đọc các file f và gán kết quả cho biến d \n",
    "                d = f.read()\n",
    "            # Sửa chữa các lỗi ký tự unicode trong danh sách trong biếm d bằng cahs sử dụng \n",
    "            # ftfy.fix_text với tham số NFKC chỉ định chuẩn hóa unicode được áp dụng \n",
    "            d = ftfy.fix_text(d, normalization='NFKC')\n",
    "            # sử dụng encode để mã hóa và biến danh sách d thành 1 danh sách số nguyên dạng int32\n",
    "            data = np.array(enc.encode(d), np.int32)\n",
    "            # Kiểm tra xem mảng data có độ dài nhỏ hơn minimum_size hoặc toàn bộ phần tử bằng 0 \n",
    "            # hay không \n",
    "            if data.shape[0] < minimum_size  or (data == 0).all(): # nếu văn bản ngắn hơn 25 tokens hoặc nhỏ hơn all tokens = 0 , ta bỏ qua \n",
    "                continue \n",
    "            \n",
    "            # khởi tạo biến hash gán nó bằng kết quả của phép tách split từ chuỗi cuối cùng \n",
    "            # từ định dnag / đầu tiên sau đó tách đôi chuỗi đó từ dấu chấm ta lấy phần đầu tiên \n",
    "            # kết quả biến hash chứa tên các file vd (file1 , file2)\n",
    "            hash = fn.split(\"/\")[-1].split(\".\")[0]\n",
    "            # Khởi tạo một từ điển tên là feature chứa 2 cặp key và value \n",
    "            feature = {\n",
    "                # với key hash có values là tên các tệp được trích xuất dưới dạng các chuỗi byte\n",
    "                # bằng cách sử dụng _bytes_feature mã hóa \n",
    "                \"hash\" : _bytes_feature(hash.encode()),\n",
    "                # Và key text có values là dữ liệu văn bản được mã hóa dưới dạng danh sách số nguyên int64  \n",
    "                # được mã hóa bằng cách sử dụng _int64_feature \n",
    "                \"text\": _int64_feature(data)\n",
    "\n",
    "            }\n",
    "\n",
    "            # tạo một đối tượng TFRecords Example là một định dạng được sử dụng để lưu trữ dữ liệu \n",
    "            # cho việc huấn luyện mô hình \n",
    "            tf_example = tf.train.Example(features= tf.train.Features(feature=feature))\n",
    "            # ghi đối tượng tf_example đã tạo vào đối tượng ghi đầu ra write . \n",
    "            # gọi phương thức Sẻializetostring để chuyển đổi toàn bộ đối tượng tf_example \n",
    "            # bao gồm các từ điển và dữ liệu lồng nhau thành một chuỗi biểu diễn nhị phân \n",
    "            # Điều anyf cần thiết vì tập TFRecord lưu trữ dữ liệu ở định dạng nhị phân \n",
    "            writer.writer(tf_example.SerilizeToString())\n",
    "            # sau đó tăng biến đếm tệp sử lý lên 1 \n",
    "            good_files += 1 \n",
    "\n",
    "    # File Complete \n",
    "    # mở 1 file trong thư mục log_dir với tên được tạo từ biến s đặt chỉ đingj chế độ mở để \n",
    "    # ghi đè nội dung cũ \n",
    "    with open(os.path.join(log_dir,s), \"w\") as f: \n",
    "        # ghi một nội dung vào file đã mở gồm số lượng file sư lý thành công \n",
    "        # và tổng số file trong chunk \n",
    "        f.write(\"{} / {}\".format(str(good_files), str(len(chunk))))\n",
    "\n",
    "    # Mở 1 file khác trong thư mục log_dir tên là good_file chữ a chỉ định chế độ mở \n",
    "    # để thêm nội dung vào cuối file thay vì ghi đè \n",
    "    with open(os.path.join(log_dir, \"good_files.log\"), \"a\") as f : \n",
    "        # ghi một nội dung vào cuối file với i chỉ số của chunk , số good_file, \n",
    "        # tổng số file trong chunk \n",
    "        f.write(\"{}: {} / {}\".format(str(i), str(good_files), str(len(chunk))))\n",
    "    \n",
    "    # trả về kết quả biến good_file \n",
    "    return good_files\n",
    "\n",
    "# Lấy thời gian hiện tại (tính theo giây) bằng hàm time.time().\n",
    "# Giá trị này được lưu vào biến start để sử dụng sau đó tính toán thời gian thực hiện.\n",
    "start = time.time()\n",
    "# Tạo một biến pool tiến trình xử lý bằng thư viện multiprocessing \n",
    "# biến processes xác định số tiến trình sẽ được sử dụng song song \n",
    "pool = Pool(processes = processes)\n",
    "# khởi tạo một biến good để lưu trữ tổng số file đã xử lý \n",
    "good = 0\n",
    "\n",
    "# lặp qua dnah sách các file được chia thành từng chunk   gán kết quả cho biến g \n",
    "# Sử dụng pool.imap để thực hiện đa xử lý phương thức create_file cho từng phần tử file_chunk \n",
    "# với số lượng cần sử lý len(file_chunk)\n",
    "for g in tqdm(pool.imap(create_file, enumerate(file_chunks)), total=len(file_chunks)):\n",
    "    # sau khi xử lý xong số lượng các  file chunk và phần phần tử trong file chunk \n",
    "    # ta cộng giá trị g vào biến good \n",
    "    good += g \n",
    "\n",
    "# Lấy thời gian thực sau khi xử lý kết thúc ghi vào biến end \n",
    "end = time.time()\n",
    "\n",
    "# ghi ra mà hình thông tin thời ian bắt đầu , kết thúc trình xử lý , số lượng file  đã xử lý tốt \n",
    "# số lượng file trên tổng số \n",
    "print(\"Done! In {:.2f}s, {} / {} good files.\".format(end-start, str(good), str(len(files))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
