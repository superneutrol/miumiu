{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from glob import glob\n",
    "import os.path as op \n",
    "import argparse , time , tarfile \n",
    "import multiprocessing as mpl \n",
    "from hashlib import md5 \n",
    "\n",
    "import os   \n",
    "import tarfile \n",
    "import re \n",
    "import newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một đối tượng ArgumentParser để chứa các đặc tả đối sốvaf các tùy chọn áp dụng cho bộ \n",
    "# phân tích \n",
    "parser = argparse.ArgumentParser()\n",
    "# Thêm 1 đối số tùy chọn có tên là --html_archive, kiểu là chuỗi và giá trị mặc định là \n",
    "# \"openwebtext/RS_2017-04-4_data.xz\". Đối tượng này sẽ được lưu trong thuộc tính html_archive \n",
    "parser.add_argument(\"--html_archive\", type=str, default=\"openwebtext/RS_2017-04-4_data.xz\")\n",
    "# Thêm một đôi số tùy chọn có tên là --chunk_size kiểu số nguyên và giá trị mặc định \n",
    "# là 100 . Đối số anyf được lưu trong thuộc tính --chunk_size của đối tượng kết quả\n",
    "parser.add_argument(\"--chunk_size\", type=int, default=100)\n",
    "# Thêm một đối số tùy chọn có tên là --n_procs kiểu số nguyên và giá trị mặc định là 5 \n",
    "# Đối số này được lưu trong thuộc tính n_procs của đối tượng kết quả \n",
    "parser.add_argument(\"--n_procs\", type=int, default=5)\n",
    "# Thêm một đối số tùy chọn có tên là --output_dir, kiểu str và giá trị mặc định là parsed. \n",
    "# Đối số này được lưu trong thuộc tính output_dir của đối tượng kêt quả\n",
    "parser.add_argument(\"--output_dir\", type=str , default=\"parsed\")\n",
    "# Chạy bộ phân tích và đặt dữ liệu được trích xuất trong một đối tượng argpase.Namespace. Đối \n",
    "# tượng này có các thuộc tính tương ứng với các đối số được định nghĩa \n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập phương thức parse_file . Nhận một đối số là một tuple gồm tên file và nội dung HTML \n",
    "# của file đó . Hàm này sẽ tạo một hash có nội dung HTML bằng thuật toán MD5 , và sử dụng hash đó \n",
    "# làm url cho một đối tuowngj Artical của thư viện newspaper. \n",
    "def parse_file(file_entry):\n",
    "    # Gán filename và html bằng 2 phần tử của tuple file entry. \n",
    "    file_name , html = file_entry\n",
    "    # Tạo một hash của nội dung HTML bằng thuật toán MD5 và lưu vào biến url_hash \n",
    "    url_hash = md5(html).hexdigest()\n",
    "    # Tạo một đối tượng Article của thư viện newspaper với url là url_hash và không tải ảnh \n",
    "    article = newspaper.Article(url = url_hash, fetch_image=False)\n",
    "    # Thiết lập nội dung HTML cho đối tượng Article bằng phương thức set_html \n",
    "    article.set_html(html)\n",
    "    # Phân tích văn bản HTML bằng phương thức parse \n",
    "    article.parse()\n",
    "    # Trả về 1 tuple gồm file và văn bản đã được phân tích \n",
    "    return (file_name, article.text)\n",
    "\n",
    "\n",
    "# Thiết lập phương thức save_parsed_text hàm này nhận hai đối ố là một dnah scahs các typle bao gồm \n",
    "# tên các file và văn bản đã được phân tích , và một đường dẫn thư mục đầu ra. \n",
    "# Hàm này sẽ duyệt qua danh sách các tuplevaf lưu văn bản vào file có cùng tên với file HTML ban đầu \n",
    "# trong thư mục đầu ra .\n",
    "def save_parsed_text(parsed_entries, out_dir):\n",
    "    # duyệt qua 1 danh sách tuple parsed_entries lấy ra file name và văn bản đã được phân tich \n",
    "    for fn , txt in parsed_entries: \n",
    "        # Sử dụng hàm join để nối đường dẫn đầu ra out_dir với tên file fn \n",
    "        txt_fp = op.join(out_dir, fn)\n",
    "        # mở file văn bản ở chế độ ghi, gán đối tượng cho biến handle\n",
    "        with open(txt_fp, \"w\") as handle:\n",
    "            # ghi nội dung của biến txt vào file  vào file văn bản qua biến handle \n",
    "            handle.write(txt)\n",
    "\n",
    "\n",
    "# Thiết lập phương thức get_processedfiles  Hàm này nhận một đối số alf một đường dẫn thư mục đầu ra. Hàm này sẽ trả về \n",
    "# một tập hợp các tên file đã được trích xuất văn bản có đuôi txt . Hàm này sử dụng glob để lấy \n",
    "# tất cả các file có định dạng txt \n",
    "def get_processed_files(out_dir):\n",
    "    # nối các file đầu ra đã được xử lý với định dnagj đuôi txt \n",
    "    # sau đó sử dụng hàm glob để tìm tất cả các tệp có định dạng .txt \n",
    "    parsed = glob(op.join(out_dir, \"*.txt\")) \n",
    "    # Trả về 1 tập hợp các tên file đã được trích xuất văn bản bằng cáchlấy phần cuối cùng\n",
    "    # của đường dẫn file sau khi tách bằng hàm op.split \n",
    "    return set([op.split(f)[-1] for f in parsed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập phương thức parse_archive có chức năng được sử dụng để trích xuất các \n",
    "# file HTML trong một file nén và lưu văn bản vào các file trong thư mục đầu ra \n",
    "# Hàm này nhận 4 đối số là đường dẫn file nén chứa các file HTML archive_fb , đường\n",
    "# dẫn đến thư mục đầu ra out_dir, số lượng tiến trình song song n_procs, và kích thước mỗi đoạn \n",
    "# file chunk_size \n",
    "def parse_archive(archive_fb , out_dir, n_procs, chunk_size=100):\n",
    "    # gọi hàm get_parsed_files để lấy tập hợp tên các file đã được trích xuất văn bản \n",
    "    # từ đường dẫn out_dir\n",
    "    processed = get_processed_files(out_dir=out_dir)\n",
    "    # mở file và gán nó cho biến tf các file HTML có định dạng tar nên ta dùng tarfile.OPEN\n",
    "    with tarfile.Open(archive_fb, \"r\") as tf: \n",
    "        # lấy ra dnah sách tên file trong file nén bằng hàm tf.getnames \n",
    "        # bỏ qua các tên file đax được tríc xuất văn bản \n",
    "        files = list(set(tf.getnames()) - set(processed))\n",
    "        # kiểm tra xem só lượng file trong dnah sách files == 0:\n",
    "        if len(files) == 0:\n",
    "            # ta quay trở lại \n",
    "            return \n",
    "        # Và kiểm tra xem số lượng file đã được tríc xuất vaen bản > 0\n",
    "        if len(processed) > 0:\n",
    "            # in ra thông báo cho biết số file đã được sử lý trước\n",
    "            print(\"{} files already processed.\". format(len(processed)))\n",
    "\n",
    "        # duyệt qua số lượng files từ danh sách file html đã được trích xuất\n",
    "        # chia nó thành các phần với kích thước chunk_size \n",
    "        for ci , chunk in enumerate(chunks(files, chunk_size)):\n",
    "            # Tạo một danh sách các tuple gồm tên file và nội dung HTML của nó \n",
    "            # bằng cách sử dụng hàm tf.extractfile để đọc nội dung từ file nén,\n",
    "            file_entries = [(fn , tf.extracfile(fn).read()) for fn in chunk]\n",
    "\n",
    "            # lấy thời gian hiện tại lưu vào biến t1 \n",
    "            t1 = time.time()\n",
    "            # Tạo một danh sách các tuple gồm tên file và văn bản đã được phân tích bằng cách \n",
    "            # sử dụng hàm map và hàm parse_file để áp dụng parse_file cho mỗi phần tử \n",
    "            # trong danh scahs file_entries \n",
    "            parsed = list(map(parse_file, file_entries))\n",
    "\n",
    "            # loại bỏ đi typle có văn bản rỗng  \n",
    "            parsed = [p for p in parsed if len(p)[1] != 0]\n",
    "\n",
    "            # Tính tỷ lệ thành công của việc trích xuất văn bản , bằng cách chia số lượng \n",
    "            # phần tử của dnah sách parsed cho số lượng phần tử của danh sách chunk * 100 \n",
    "            hit_rate = len(parsed) / len(chunk) * 100\n",
    "            #In ra thời gian đã mất để phân tích đoạn file hiện tại, và tỷ lệ thành công của việc trích xuất văn bản\n",
    "            print(\"Parsing chunk {} took {} seconds\".format(ci + 1, time.time() - t1))\n",
    "            print(\" -- {}% of chunk {}'s docs yielded text.\".format(hit_rate, ci + 1))\n",
    "\n",
    "            # lấy thời gian hiện tại lưu vào biến t1\n",
    "            t1 = time.time()\n",
    "            # Gọi hàm save_parsed_text để lưu các tupel trong danh sách parsed vào các file văn bản \n",
    "            # trong thư mục đầu ra \n",
    "            save_parsed_text(parsed, out_dir)\n",
    "            # In ra thời gian đã mất để lưu đoạn file hiện tại.\n",
    "            print(\"Saving chunk {} took {} seconds\".format(ci + 1, time.time() - t1))\n",
    "\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i : i + n]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập phương thức extract_month . Hàm này là một hàm để trích xuất thánh từ tên file chứa url \n",
    "# Hàm này nhận một đối số là tên file và trả về chuỗi là tháng \n",
    "def extract_month(url_file_name):\n",
    "    # Tạo một biểu thức chính quy month_re để khớp với các chuỗi có dạng RS_ theo sau là 4 chữ số,\n",
    "    # dấu gạch ngang, và 2 chữ số. Ví dụ: RS_2017-04.\n",
    "    month_re = r\"(RS_.*2\\d{3}-\\d{2})\"\n",
    "    # tách tên file từ đường dẫn url và lưu nó vào biến month \n",
    "    month = op.split(url_file_name)[-1]\n",
    "    # Áp dụng biểu thức chính quy month_re cho biến month  bằng hàm re.match \n",
    "    # và lấy kết quả khớp bằng phương thức group lưu lại vào biến month \n",
    "    month = re.match(month_re, month).group()\n",
    "    # trả về month là kết qủa của hàm \n",
    "\n",
    "\n",
    "# Thiết lập phương thức extract_archive Hàm này nhận hai đối số là đường dẫn đến file nén\n",
    "# chứa các file HTML (archive_fp), và đường dẫn đến thư mục đầu ra (outdir). \n",
    "def extract_archive(archive_fb,outdir=\".\"):\n",
    "    # sử dụng tarfile.Open để mở cac file HTML có định dạng .tar gán cho biến tar\n",
    "    with tarfile.Open(archive_fb, \"r\") as tar:\n",
    "        # giải nén tất acr accs file trong file nén vào thư mục đầu ra bằng \n",
    "        # tar.extractall \n",
    "        tar.extractall(outdir)\n",
    "    \n",
    "    return outdir \n",
    "\n",
    "# Thiết lập phương thức makedir để kiểm tra và tạo thư mục \n",
    "def mkdir(fp):\n",
    "    # kiểm tra xem fp có phải là thư mục đã tồn tại \n",
    "    if not op.exits(fp):\n",
    "        # nếu không sử dụng makedir để biến nó thành 1 thư mục \n",
    "        os.makedirs(fp)\n",
    "    return fp \n",
    "\n",
    "\n",
    "\n",
    "# kiểm tra xem file Python có được chạy trực tiếp hay không \n",
    "# nếu có khối lệnh trong nó sẽ được thực hiện \n",
    "if __name__ == \"__main__\":\n",
    "    # Gọi hàm extract_month để trích xuất tháng từ tên file chứa url, lưu vào biến month.\n",
    "    month = extract_month(args.html_archive)\n",
    "    # : Gọi hàm mkdir để tạo một thư mục đầu ra có tên là tháng đã trích xuất, lưu vào biến out_dir.\n",
    "    out_dir = mkdir(op.join(args.output_dir, month))\n",
    "    # Gọi hàm parse_archive để trích xuất văn bản từ các file HTML trong file nén, \n",
    "    # và lưu văn bản vào các file trong thư mục đầu ra.\n",
    "    parse_archive(args.html_archive, out_dir, args.n_procs, args.chunk_size)\n",
    "    #  In ra màn hình chuỗi “Done!” để báo hiệu quá trình trích xuất văn bản đã hoàn tất.\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
