{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import nbimporter\n",
    "\n",
    "from GPT_2 import gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập phương thức lấy mẫu dữ liệu top k \n",
    "def top_k_logits(logits, k):\n",
    "    if k == 0:\n",
    "        # không cắn ngắn \n",
    "        return logits \n",
    "    \n",
    "    # xây dựng hàm top_k xử lý \n",
    "    def _top_k():\n",
    "        # lấy ra gía trị và chỉ số của phép lấy mẫu top_k \n",
    "        # từ kết quả của tensor logits \n",
    "        value, _ = tf.nn.top_k(logits, k=k) \n",
    "        # lấy giá trị nhỏ nhất của danh sách value (giá trị cuối cùng trong hàng)\n",
    "        # và thêm 1 trục mới vào . Điều này tạo ra một tensor có cùng số lượng\n",
    "        # hàng như values nhưng chỉ có một cột.\n",
    "        min_values = value[:, -1, tf.newaxis]\n",
    "        # hàm tf.where kiểm tra điều kiện logits < min_values nếu điêu kiện đúng \n",
    "        # nó sẽ lấy giá trị thứ 2 tf.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
    "        # nếu điều kiện sai nó sẽ giữ nguyên logits . Tensor thứ 2 này được tạo ra bằng \n",
    "        # cách nhân tensor của các số 1 có cùng hình dnagj với logits với 1e-10\n",
    "        return tf.where(\n",
    "            logits < min_values,\n",
    "            tf.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
    "            logits,\n",
    "        )\n",
    "    # cuối cùng sử dụng tf.cond (conditional) kiểm tra xem k có  = 0\n",
    "    # nếu k = 0 sẽ trả về logits không thay đổi \n",
    "    # nếu  không thì gọi hàm top_k và áp dụng các bước trên \n",
    "    return tf.cond(\n",
    "       tf.equal(k, 0),\n",
    "       lambda: logits,\n",
    "       lambda: _top_k(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thiết lập phương thức lấy mẫu tuần tự \n",
    "def sample_sequence(*, params, length, start_token=None, batch_size=None, context=None,temperature=1, top_k=0):\n",
    "    # kiểm tra xem start_tokens = True \n",
    "    if start_token is None:\n",
    "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
    "        'Chỉ định chính xác 1 trong start_token và bối cảnh'\n",
    "    # trường hợp còn lại \n",
    "    else:\n",
    "        # kiểm tra điều kiện tương tụ \n",
    "        assert context is None, 'Specify exactly one of start_token and context!'\n",
    "        # tạo một tensor mới bằng cachs sao chép danh sách start token ténor shap[batch_size,1]\n",
    "        context = tf.fill([batch_size, 1], start_token)\n",
    "\n",
    "        # tạo một biến length gán cho nó kết quả của length - giá trị nguyên khóa text_length \n",
    "        # trong từ điển params \n",
    "        length = length - params[\"text_len\"]\n",
    "\n",
    "    # thiết lập phương thức xủ lý model \n",
    "    # token là tensor tokens đầu vào past là tensor chứa các thông tin đã được huấn luyện \n",
    "    # ở bước trước đó \n",
    "    def step(params, tokens , past=None):\n",
    "        # kiểm tra xem chế độ percision (độ chính xác) có đang sử dụng kiểu bfloat 16\n",
    "        if params['percision'] == 'bfloat16':\n",
    "            # khởi tạo một biến phạm vi \n",
    "            with tf.contrib.tpu.bfloat16_scope():\n",
    "                # thực hiện xử lý gpt model gán kết quả cho biến lm_output\n",
    "                lm_output = gpt2.model(params=params, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n",
    "\n",
    "            # ghi vào khóa nhật ký của lm_output giá trị của chính nó nhưng kiểu dữ liệu là float32\n",
    "            lm_output[\"logits\"] = tf.cast(lm_output[\"logits\"], tf.float32)\n",
    "        # trường hợp còn lại \n",
    "        else:\n",
    "            # thực hiện tương tự \n",
    "            lm_output = lm_output = gpt2.model(params=params, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n",
    "\n",
    "        # lấy kích thước của tensor lm_output = kích thước của khóa n_vocab trong từ điển params \n",
    "        # là kích thước của tập từ vựng \n",
    "        logits = lm_output['logits'][:, :, params['n_vocab']]\n",
    "        # lấy kết quả của từ điển lm_output khóa present là kết quả hiện tại \n",
    "        # gán lại cho biến present\n",
    "        presents = lm_output['present']\n",
    "        # đặt hình dạng cho tensor presents dựa trên hình dạng mong đợi, được tính toán từ hàm gpt2.past_shape. Điều này cần thiết để đảm bảo rằng tensor\n",
    "        # presents có hình dạng đúng khi được truyền vào mô hình cho các bước tiếp theo.\n",
    "        presents.set_shape(gpt2.past_shape(params=params, batch_size=batch_size))\n",
    "        # trả về 1 từ điển 2 khóa là logits và present \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'presents': presents,\n",
    "        }\n",
    "    \n",
    "    # khởi tạo biến phạm vi name_scope là phạm vi hoạt động \n",
    "    # có tên là sample_sequence\n",
    "    with tf.name_scope(\"sample_sequence\"):\n",
    "\n",
    "        # tạo ra một đầu ra từ step lấy tất acr phần tử từ danh sách trừ phần tử cuối cùng \n",
    "        context_output = step(params, context[:, :-1])\n",
    "        # xây dựng phương thức body là một hàm được lặp đi lặp lại trong quá trình tạo mẫu chuỗi \n",
    "        def body(past, prev, output):\n",
    "            #tạo ra đầu ra tiếp theo từ hàm step \n",
    "            # prev[:, tf.newaxis]: Một tensor mới được tạo từ prev bằng cách thêm một chiều mới,\n",
    "            # giúp chuẩn bị dữ liệu cho bước tiếp theo của quá trình dự đoán.\n",
    "            next_outputs = step(params, prev[:, tf.newaxis], past=past)\n",
    "            # trích xuất giá trị đầu ra logits của hàm step trước khi áp dụng hàm softmax\n",
    "            # next_outputs['logits][:, -1, :] lấy logits cuủa phần tử cuối cùng trong step \n",
    "            # Chia các logits cho temperature, một giá trị dương, để kiểm soát sự phân phối của các mẫu được sinh ra. K\n",
    "            logits = next_outputs['logits'][:, -1, :]  / tf.to_float(temperature)\n",
    "            # lấy mẫu top_k  Giới hạn logits để chỉ xem xét top_k giá trị cao nhất,\n",
    "            # giúp tập trung vào các lựa chọn có khả năng cao nhất.\n",
    "            logits = top_k_logits(logits, k=top_k)\n",
    "            # lấy mẫu từ phân phối xác suất được định nghĩa bởi logits \n",
    "            # Khi hàm tf.multinomial được thực thi, nó sẽ chọn một mẫu từ phân phối xác suất \n",
    "            # dựa trên các logits đã cho. Mỗi mẫu được lấy một cách ngẫu nhiên,\n",
    "            # nhưng với xác suất tương ứng với giá trị của logits\n",
    "            samples = tf.multinomial(logits, num_samples=1, output_dtype=tf.int32)\n",
    "            # trả về kết quả  đầu \n",
    "            return [\n",
    "                # nối 2 tensor past và giá trị present trong từ điển next_output theo chiều axis = -2\n",
    "                tf.concat([past, next_outputs['presents']], axis=-2),\n",
    "                # bỏ đi chiều thứ 2 trong tensor samples\n",
    "                tf.squeeze(samples, axis=[1]),\n",
    "                # nối tensor output với samples \n",
    "                tf.concat([output, samples], axis=1),\n",
    "            ]\n",
    "        \n",
    "        # def cond: Hàm điều kiện luôn trả về True, cho phép vòng lặp tiếp tục không giới hạn.\n",
    "        def cond(*args):\n",
    "            return True \n",
    "        \n",
    "\n",
    "        # Phần tiếp theo của đoạn mã TensorFlow này sử dụng hàm tf.while_loop \n",
    "        # để lặp đi lặp lại một chuỗi các bước tính toán cho đến khi một điều kiện nhất định không còn đúng nữa hoặc đạt đến số lần lặp tối đa.\n",
    "        _, _, tokens = tf.while_loop(\n",
    "            # cond=cond: Điều kiện để tiếp tục vòng lặp. Trong trường hợp này, cond luôn trả về True, \n",
    "            # nên vòng lặp sẽ tiếp tục cho đến khi đạt đến maximum_iterations.\n",
    "\n",
    "            # Hàm body chứa logic để thực hiện mỗi lần lặp. \n",
    "            # Nó sẽ sử dụng các biến loop_vars và trả về kết quả mới cho mỗi lần lặp.\n",
    "            cond=cond, body=body,\n",
    "            # Nó sẽ sử dụng các biến loop_vars và trả về kết quả mới cho mỗi lần lặp.\n",
    "            # Nó sẽ sử dụng các biến loop_vars và trả về kết quả mới cho mỗi lần lặp.\n",
    "            maximum_iterations=length,\n",
    "            # Một danh sách các biến sẽ được truyền vào hàm body và được cập nhật sau mỗi lần lặp.\n",
    "            loop_vars=[\n",
    "                context_output['presents'],\n",
    "                context[:, -1],\n",
    "                context,\n",
    "            ],\n",
    "            # Một danh sách các tf.TensorShape xác định hình dạng không đổi của các\n",
    "            # tensor trong loop_vars qua mỗi lần lặp. Điều này giúp \n",
    "            # TensorFlow kiểm soát hình dạng của các tensor và đảm bảo tính nhất quán.\n",
    "            shape_invariants=[\n",
    "                tf.TensorShape(gpt2.past_shape(params=params, batch_size=batch_size)),\n",
    "                tf.TensorShape([None]),\n",
    "                tf.TensorShape([None, None]),\n",
    "            ],\n",
    "            # Đặt back_prop thành False để ngăn chặn việc tính toán gradient qua vòng lặp này,\n",
    "            # thường được sử dụng trong quá trình dự đoán hoặc tạo mẫu, \n",
    "            # không phải trong quá trình huấn luyện.\n",
    "            back_prop=False,\n",
    "        )\n",
    "        # Cuối cùng, sau khi vòng lặp kết thúc, tensor tokens sẽ được trả về. tokens \n",
    "        # chứa chuỗi các phần tử (ví dụ: từ hoặc ký tự) đã được tạo mẫu qua vòng lặp.\n",
    "        return tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
