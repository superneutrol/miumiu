{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "# Xây dựng phươngt thức tối ưu hóa qua trình đào tạo cho mô hình \n",
    "def create_train_op(loss, params): \n",
    "    # Lấy ra tham số lr của kháo lr từ , từ điển params \n",
    "    lr = params['lr']\n",
    "    # kiểm tra xem giá trị warmup_steps trong từ điển params có = True không \n",
    "    # có nghĩa là mô hình co đang khởi động sẵn sàng hay không . \n",
    "    if \"warmup_steps\"  in params.key():\n",
    "        # gán cho lrr bằng  giá trị của phuuwong thức cosine_decay_with warp \n",
    "        # phuuwong thức này cho phép phân dã tỷ lệ lr với mỗi bước warmup \n",
    "        r = cosine_decay_with_warmup(tf.train.get_global_step(), lr,\n",
    "                                        params[\"max_steps\"], warmup_steps=params[\"warmup_steps\"])\n",
    "\n",
    "    # kiểm tra xem trình tối ưu hóa của training có phải là adam \n",
    "    if params[\"opt_name\"] == \"adam\":\n",
    "        # kiểm tra xem weight_decay có trong từ điển params \n",
    "        if not \"weight_decay\" in params.keys():\n",
    "            # Ta xây dựng trình tối ưu hóa adam \n",
    "            optimizer = tf.train.AdamOptimizer(\n",
    "                lerning_rate = lr, \n",
    "                beta1 = params[\"beta1\"], \n",
    "                beta2 = params[\"beta2\"],\n",
    "                epsilon=params[\"epsilon\"]\n",
    "            )\n",
    "        \n",
    "        # Trường hợp còn lại sử dụng AdamWOptimizer \n",
    "        else: \n",
    "            optimizer = tf.contrib.opt.AdamWOptimizer(\n",
    "                learning_rate=lr,\n",
    "                weight_decay=lr*params[\"weight_decay\"],\n",
    "                beta1=params[\"beta1\"],\n",
    "                beta2=params[\"beta2\"],\n",
    "                epsilon=params[\"epsilon\"])\n",
    "    # TRường hợp params[\"opt_name\"] == \"adafactor\"\n",
    "    elif params[\"opt_name\"] == \"adafactor\":\n",
    "        # kiểm tra khóa \"decay_type\" == adam\n",
    "        if params[\"decay_type\"] == \"adam\":\n",
    "            # nếu có ta tính một tỷ lệ phân giã chuyền vào nó tham số beta2 của \n",
    "            # từ điển params \n",
    "            decay_rate = adafactor_decay_rate_adam(params[\"beta2\"])\n",
    "        #  nêu như = pow\n",
    "        elif params[\"decay_type\"] == \"pow\":\n",
    "            # ta thực hiện như trên nhưng với tham số exponent \n",
    "            decay_rate = adafactor_decay_rate_pow(params[\"decay_exponent\"])\n",
    "        # trường hợp còn lại đưa ra cảnh báo \n",
    "        else:\n",
    "            raise ValueError(\"unknown optimizer_adafactor_decay_type\")\n",
    "        # nếu weight_decay không có trong từ điển \n",
    "        if not \"weight_decay\" in params.keys():\n",
    "            # sử dụng tối ưu hóa AdafactorOptimizer\n",
    "            optimizer = AdafactorOptimizer(\n",
    "                # Truyền vào các tham số lrr \n",
    "                learning_rate=lr,\n",
    "                # tỷ lệ phân dã \n",
    "                decay_rate=decay_rate,\n",
    "                # tham số beta\n",
    "                beta1=params[\"beta1\"],\n",
    "                name=\"Adafactor\")\n",
    "        else:\n",
    "            # đưa ra sử dụng một hàm từ Tensorflow để mửo rộng một lớp tối ưu hóa trong \n",
    "            # trường hợp này là AdafactorOptimizer. Hàm extend_with_decoupled_weight_decay\n",
    "            # Thêm tính năng suy giảm trọng số không phụ thuộc vào lớp tối ưu hóa ban đầu \n",
    "            # điều này có nghĩa là có thể áp dụng giảm trọng sôs weight_decay mà không ảnh hưởng \n",
    "            # đến quá trình cập nhật Gradient trong trình huấn luyện\n",
    "            AdafactorWOptimizer = tf.contrib.opt.extend_with_decoupled_weight_decay(AdafactorOptimizer)\n",
    "\n",
    "            # User Optimizer AdafactorWOptimizer \n",
    "            optimizer = AdafactorWOptimizer(\n",
    "                weight_decay=params[\"weight_decay\"] * lr,\n",
    "                learning_rate=lr,\n",
    "                decay_rate=decay_rate,\n",
    "                beta1=params[\"beta1\"],\n",
    "                name=\"AdafactorW\")\n",
    "\n",
    "    else:\n",
    "        # trường hợp còn lại đưa ra 1 cảnh báo \n",
    "        raise ValueError(\"Unknown optimizer type!\")\n",
    "\n",
    "    # kiểm tra xem trình tối ưu có đang sử dụng TPU không \n",
    "    if params[\"use_tpu\"]:\n",
    "        # Phân bổ dữ liệu thông qua các phân mảnh TPU cho việc tối ưu hóa \n",
    "        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "\n",
    "    # CẬP nhật trình tối ưu hóa cho mô hình \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # To update batchnorm, if present\n",
    "    # Tối ưu hóa hàm loss cho trình tối ưuu\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    # sử dụng tf.group để nhóm các nhóm tham số train và update \n",
    "    train_op = tf.group([train_op, update_ops])\n",
    "\n",
    "    # Trả về kết quả của train_op \n",
    "    return train_op\n",
    "\n",
    "\n",
    "\n",
    "# Xây dựng phương thức cơ chức năng phân rã trọng số tỷ lệ học tập lr\n",
    "def cosine_decay_with_warmup(global_step,\n",
    "                             learning_rate_base,\n",
    "                             total_steps,\n",
    "                             warmup_learning_rate=0.0,\n",
    "                             warmup_steps=0,\n",
    "                             hold_base_rate_steps=0,\n",
    "                             name=\"learning_rate\"):\n",
    "    # kiểm tra xem tổng các bước có nhỏ hơn số bước khởi động hy không \n",
    "    if total_steps < warmup_steps: \n",
    "        # Đưa ra một cảnh báo \n",
    "        raise ValueError('total_steps must be larger or equal to '\n",
    "                        'warmup_steps.')\n",
    "    \n",
    "    # Tính tỷ lệ học tập mới dựa trên cơ sở tỷ lệ học tập và số bước đã thực hiện \n",
    "    # Hàm tf.cos tạo ra một hàm giảm dần theo chu kỳ của hàm cosine giúp tỷ lệ học tập \n",
    "    # giảm một cachs mượt mà theo thời gian \n",
    "    learning_rate = 0.5 * learning_rate_base * (1 + tf.cos(\n",
    "        np.pi *\n",
    "        (tf.cast(global_step, tf.float32) - warmup_steps - hold_base_rate_steps\n",
    "        ) / float(total_steps - warmup_steps - hold_base_rate_steps)))\n",
    "    \n",
    "    # nếu có bước giữ tỷ lệ cơ sỏ (hold_base_rate_steps) > 0\n",
    "    # tywr lệ học tập sẽ được giữ nguyên là learning_rate_base cho đến khi số \n",
    "    # bước vượt qua ngưỡg này \n",
    "    if hold_base_rate_steps > 0:\n",
    "        learning_rate = tf.where(\n",
    "            # kiểm tra xem điều kiện đúng , nếu dúng dữ nguyên là lr, còn không \n",
    "            # tỷ lệ này sẽ được giữ nguyên là lrrb\n",
    "            global_step > warmup_steps + hold_base_rate_steps, learning_rate, \n",
    "            learning_rate_base\n",
    "\n",
    "        )\n",
    "    # nếu như warmup_steps  > 0 :\n",
    "    if warmup_steps > 0:\n",
    "        # kiểm tra xem lr_base < warmup_lr không \n",
    "        if learning_rate_base < warmup_learning_rate:\n",
    "            # nếu có đưa ra một cảnh báo \n",
    "            raise ValueError('learning_rate_base must be larger or equal to '\n",
    "                        'warmup_learning_rate.')\n",
    "        # sau đó tạo một biến slope \n",
    "        slope = (learning_rate_base - warmup_learning_rate) / warmup_steps\n",
    "        # nhân slop với global_step + warmup_lr\n",
    "        warmup_rate = slope * tf.cast(global_step,\n",
    "                                    tf.float32) + warmup_learning_rate\n",
    "        # kiểm tra  một điều kiện nếu đúng ta giữ nguyên giá trị của warmup_rate \n",
    "        # nếu không giữ nguyên giá trị lr\n",
    "        learning_rate = tf.where(global_step < warmup_steps, warmup_rate,\n",
    "                                learning_rate)\n",
    "    # cuối cùng kiểm tra điều kiện và trả về kết quả tương ứng                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "    return tf.where(global_step > total_steps, 0.0, learning_rate,\n",
    "                    name=name)\n",
    "\n",
    "\n",
    "\n",
    "# Adafactor from tensor2tensor -------------------------------------------------------------\n",
    "\n",
    "class AdafactorOptimizer(tf.train.Optimizer):\n",
    "    \"\"\"Optimizer that implements the Adafactor algorithm.\n",
    "    Adafactor is described in https://arxiv.org/abs/1804.04235.\n",
    "    Adafactor is most similar to Adam (Kingma and Ba), the major differences are:\n",
    "    1. For a two-dimensional AxB weight matrix, Adafactor uses only A+B auxiliary\n",
    "        parameters to maintain the second-moment estimator, instead of AB.\n",
    "        This is advantageous on memory-limited systems.  In addition, beta1\n",
    "        (momentum) is set to zero by default, saving an additional auxiliary\n",
    "        parameter per weight.  Variables with >=3 dimensions are treated as\n",
    "        collections of two-dimensional matrices - factorization is over the final\n",
    "        two dimensions.\n",
    "    2. Adafactor incorporates \"update-clipping\" - a scale-invariant analog of\n",
    "        gradient clipping.  This adds stability\n",
    "    3. Adafactor does not require an external \"learning rate\".  By default, it\n",
    "        incorporates a relative-update-scale schedule, corresponding to\n",
    "        inverse-square-root learning-rate-decay in ADAM.  We hope this works well\n",
    "        for most applications.\n",
    "    ALGORITHM:\n",
    "    parameter -= absolute_update_scale * clip(grad / grad_scale)\n",
    "    where:\n",
    "        absolute_update_scale := relative_update_scale * parameter_scale\n",
    "        relative_update_scale := min((step_num + 1)**-0.5, 1e-2)\n",
    "        parameter_scale := max(rms(var)), epsilon2)\n",
    "        clip(x) := x / max(1.0, rms(x))\n",
    "        grad_scale := tf.sqrt(v)   (v is the second-moment estimator)\n",
    "    The second-moment estimator v is maintained in a manner similar to Adam:\n",
    "    We initialize\n",
    "    ```\n",
    "    if var is 2-dimensional:\n",
    "        v_r <- zeros([num_rows])\n",
    "        v_c <- zeros([num_cols])\n",
    "    if var is 0-dimensional or 1-dimensional:\n",
    "        v <- zeros(shape(var))\n",
    "    ```\n",
    "    The update rule is as follows:\n",
    "    ```\n",
    "    decay_rate = 1 - (step_num + 1) ^ -0.8\n",
    "    grad_squared = tf.square(grad) + epsilon1\n",
    "    if var is 2-dimensional:\n",
    "        v_r <- decay_rate * v_r + (1 - decay_rate) * reduce_mean(grad_squared, 1)\n",
    "        v_c <- decay_rate * v_c + (1 - decay_rate) * reduce_mean(grad_squared, 0)\n",
    "        v = outer_prod(v_r, v_c) / reduce_mean(v_r)\n",
    "    if var is 0-dimensional or 1-dimensional:\n",
    "        v <- decay_rate * v + (1 - decay_rate) * grad_squared\n",
    "    ```\n",
    "    For variables with >=3 dimensions, we factorize the second-moment accumulator\n",
    "    over the final 2 dimensions.  See the code for details.\n",
    "    Several parts of this algorithm are configurable from the initializer.\n",
    "        multiply_by_parameter_scale:  If True, then compute absolute_update_scale\n",
    "        as described above.  If False, let absolute_update_scale be the externally\n",
    "        supplied learning_rate.\n",
    "        learning_rate: represents relative_update_scale if\n",
    "        multiply_by_parameter_scale==True, or absolute_update_scale if\n",
    "        multiply_by_parameter_scale==False.\n",
    "        decay_rate: Decay rate of the second moment estimator (varies by step_num).\n",
    "        This should be set to a function such that:\n",
    "        1-1/(step_num + 1) <= decay_rate(step_num) < 1.0\n",
    "        beta1: enables momentum, as in Adam.  Uses extra memory if nonzero.\n",
    "        clipping_threshold: should be >=1.0 or None for no update clipping\n",
    "        factored: whether to factor the second-moment estimator.  True means\n",
    "        less memory usage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                multiply_by_parameter_scale=True,\n",
    "                learning_rate=None,\n",
    "                decay_rate=None,\n",
    "                beta1=0.0,\n",
    "                clipping_threshold=1.0,\n",
    "                factored=True,\n",
    "                use_locking=False,\n",
    "                name=\"Adafactor\",\n",
    "                epsilon1=1e-30,\n",
    "                epsilon2=1e-3):\n",
    "        \"\"\"Construct a new Adafactor optimizer.\n",
    "        See class comment.\n",
    "        Args:\n",
    "        multiply_by_parameter_scale: a boolean\n",
    "        learning_rate: an optional Scalar.\n",
    "        decay_rate: an optional Scalar.\n",
    "        beta1: a float value between 0 and 1\n",
    "        clipping_threshold: an optional float >= 1\n",
    "        factored: a boolean - whether to use factored second-moment estimator\n",
    "            for 2d variables\n",
    "        use_locking: If True use locks for update operations.\n",
    "        name: Optional name for the operations created when applying gradients.\n",
    "            Defaults to \"AdafactorOptimizer\".\n",
    "        epsilon1: Regularization constant for squared gradient.\n",
    "        epsilon2: Regularization constant for parameter scale.\n",
    "        Raises:\n",
    "        ValueError: if absolute_update_scale and relative_update_scale_fn are both\n",
    "            present or both absent.\n",
    "        \"\"\"\n",
    "        super(AdafactorOptimizer, self).__init__(use_locking, name)\n",
    "        self._multiply_by_parameter_scale = multiply_by_parameter_scale\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self._learning_rate_default(multiply_by_parameter_scale)\n",
    "        self._learning_rate = learning_rate\n",
    "        if decay_rate is None:\n",
    "            decay_rate = self._decay_rate_default()\n",
    "        self._decay_rate = decay_rate\n",
    "        self._beta1 = beta1\n",
    "        self._clipping_threshold = clipping_threshold\n",
    "        self._factored = factored\n",
    "        self._epsilon1 = epsilon1\n",
    "        self._epsilon2 = epsilon2\n",
    "\n",
    "    # Thiết lập phương thức sử dụng công cụ ước tính thời đuểm thứ 2 \n",
    "    # dựa trên hình dnagj của biến và trả về 1 danh sách kiểu boolean \n",
    "    def _should_use_factored_second_moment_estimate(self, shape):\n",
    "        \"\"\"Should we use a factored second moment estimator.\n",
    "            Based on the shape of the variable.\n",
    "\n",
    "        ARGS: \n",
    "            shape: A list of intergers\n",
    "            Return: A boolean \n",
    "        \"\"\"\n",
    "        \n",
    "        return self._factored and len(shape) >= 2 \n",
    "    \n",
    "    # thiết lập phương thức create_slot để tạo các \"slot\" cho các biến \n",
    "    # các slot này được sử dụng để lưu trữ thông tin cần thiết cho quá trình tối ưu hóa \n",
    "    def _create_slots(self, var_list):\n",
    "        # duyệt qua các phần tử trong danh sách varlist \n",
    "        for var in var_list:\n",
    "            # lấy ra hình dạng của var các hình dnagj này được trả về dưới dnagj list \n",
    "            shape = var.get_shape().as_list()\n",
    "            # kiểm tra xem có sử dụng moment đầu tiên không \n",
    "            if self._beta1:\n",
    "                # tao slot cho moment đầu tiên nếu beta_1 được thiết lập \n",
    "                self._zeros_slot(var, 'm', self._name)\n",
    "            \n",
    "            # kiểm tra điều kiện nếu kích thước của gradient lớn hơn 2 và sử dụng ước lượng moment\n",
    "            # thứ 2 theo từng phần \n",
    "            if self._should_use_factored_second_moment_estimate(shape):\n",
    "                # tạo một tensor shape là kích thước theo hàng ngang \n",
    "                # type = tf.float32\n",
    "                r_var = tf.zeros(shape[:-1], dtype= tf.float32)\n",
    "                # và tạo một ma trận theo cột \n",
    "                c_var = tf.zeros(shape[:-2] + shape[-1:], dtype=tf.float32)\n",
    "                # Tạo slot cho ước lượng hàng \n",
    "                self._get_or_make_slot(var, r_var, \"vr\", self._name)\n",
    "                # tạo một slot cho ước lượng cột \n",
    "                self.get_or_make_slot(var, c_var, \"vc\", self._name)\n",
    "            \n",
    "            else: \n",
    "                # Tạo mảng zeros cho full tensor \n",
    "                v_var = tf.zeros(shape, dtype=tf.float32)\n",
    "                # Tạo slot cho moment thứ 2 \n",
    "                self._get_or_make_slot(\n",
    "                    var, v_var, \"v\", self._name\n",
    "                )\n",
    "\n",
    "    # Xây dựng các phuuwong thức để áp dụng các hàm chức năng cho việc xử lý một cách thu gọn \n",
    "    def _apply_dense(self, grad, var):\n",
    "        # áp dụng phuuwong thức resource_apply_dense cho garadient và giá trị var \n",
    "        return self._resource_apply_dense(grad, var)\n",
    "    \n",
    "    def _apply_sparse(self, grad, var):\n",
    "        return self._apply_dense(tf.convert_to_tensor(grad), var)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, handle, indices):\n",
    "        return self._resource_apply_dense(\n",
    "            tf.convert_to_tensor(tf.IndexedSlices(grad, indices, tf.shape(handle))),\n",
    "            handle)\n",
    "    \n",
    "    # Thiết lập phương thức thay đổi các tỷ lệ của tham số \n",
    "    # nhận đầu vào là biến var là một thực thể của tf.Variable . là một loại \n",
    "    # biến  đặc biệt được sử dụng trong tensorflow được sử dụng trong tensorflow \n",
    "    # để lưu trữ và cập nhật các trạng thái khi chạy mô hình \n",
    "    # là một tensor mà giá trị có thể thay đổi qua các phép biến đổi \n",
    "    def _parameter_scale(self, var):\n",
    "        \"\"\"Estimate the scale of the parameters from the current values.\n",
    "            We include a minimum value of 0.001 to give it a chance to escape 0\n",
    "        if it was zero-initialized.\n",
    "        Instead of using the value, we could impute the scale from the shape,\n",
    "        as initializers do.\n",
    "        Args:\n",
    "        var: a variable or Tensor.\n",
    "        Returns:\n",
    "        a Scalar\n",
    "        \"\"\"\n",
    "        return tf.maximum(reduce_rms(var), self._epsilon2)\n",
    "    \n",
    "    # Thiết lập phương thức resource_apply_dense để áp dụng các lớp xử lý lên \n",
    "    # gard 9laf grad của mất mát , và handle tham chiếu đến biến có thể huấn luyện mà \n",
    "    # bạn muốn cập nhật . Trong tensorflow các biến thường được quản lý thông qua các \n",
    "    # handle để tối ưu hóa hiệu suất \n",
    "    def _resource_apply_dense(self, grad, handle):\n",
    "        # gán cho var = handle \n",
    "        var = handle \n",
    "        # thay đổi kiểu datatype cho tham só grad \n",
    "        grad = tf.to_float(grad)\n",
    "        # tính bình phương của giá trị grad sau đó cộng tham ố e\n",
    "        grad_squared = tf.square(grad) + self._epsilon1\n",
    "        # Tính trung bình giá trị của bộ tham số này \n",
    "        rad_squared_mean = tf.reduce_mean(grad_squared)\n",
    "        # Định nghĩa tham số decay_rate , lr , var (tensor lưu trữ)\n",
    "        decay_rate = self._decay_rate\n",
    "        update_scale = self._learning_rate\n",
    "        old_val = var\n",
    "\n",
    "        # kiểm tra xem kểu dtype cơ sở của tensor var = bfloat16\n",
    "        if var.dtype.base_dtype == tf.float16:\n",
    "            # nếu đúng tensor này sẽ được chuyển qua kiểu float \n",
    "            # sử dụng self._parameter_encoding.decode để né / lượng tử hóa tham số pld_val \n",
    "            # Giải nén . chuyển đổi bfloat16 nén sang định dạng float32 đầy đủ \n",
    "            # Lượng tử hóa : Áp dụng các phép toán đảo ngược để khôi phục giá trị bfloat32 ban đầu \n",
    "            old_val = tf.to_float(self._parameter_encoding.decode(old_val))\n",
    "\n",
    "        # nếu có sử dụng tỷ lệ tham số \n",
    "        if self._multiply_by_parameter_scale:\n",
    "            # Nhân tỷ lệ này với tỷ lệ tham số chuyển đổi qua float32 \n",
    "            update_scale *= tf.to_float(self._parameter_scale(old_val))    \n",
    "        # HACK : tạo một sự phụ thuộc vào gard , điều này làm rối trí trình biên dịch XLA \n",
    "        # và ngăn chặn việc hợp nhất các tính toán giữa các biến khác nhau . Việc hợp nhất \n",
    "        # này không tốt cho việc sử dụng HBM vì nó khiên cho gradient tồn tại trong bộ nhớ \n",
    "        # lâu hơn cần thiết \n",
    "        ecay_rate += grad_squared_mean * 1e-30\n",
    "        update_scale += grad_squared_mean * 1e-30\n",
    "        # END HACK\n",
    "        mixing_rate = 1.0 - decay_rate\n",
    "        # Lấy ra hình dạng của tensor lưu trữ lưu dưới dạng list\n",
    "        shape = var.get_shape().as_list()\n",
    "        # tạo một danh sách để lưu trữ các giá trị dã được cập nhật \n",
    "        updates = []\n",
    "        # kiểm tra xem có sử dụng ước lượng moment bậc 2 đã đựo phân tích hay không \n",
    "        # dựa trên hình dạng của tensorflow\n",
    "        if self._should_use_factored_second_moment_estimate(shape):\n",
    "            # tính trung bình bình phương gradient theo hàng avf cột \n",
    "            grad_squared_row_mean = tf.reduce_mean(grad_squared, -1)\n",
    "            grad_squared_col_mean = tf.reduce_mean(grad_squared, -2)\n",
    "            # sau đó lấy ácc slot vr và vc liên quan đến biến var \n",
    "            vr = self.get_slot(var, \"vr\")\n",
    "            # Tính toán giá trị mới cho vr và vc dựa trên tỷ lệ suy giảm decay , tỷ lệ trộn\n",
    "            # Và trung bình , bình phương  gradient \n",
    "            new_vr = (decay_rate * vr + mixing_rate * grad_squared_row_mean)\n",
    "            vc = self.get_slot(var, \"vc\")\n",
    "            new_vc = (decay_rate * vc + mixing_rate * grad_squared_col_mean)\n",
    "            # Cập nhật giá trị cho vr và vc\n",
    "            # sử dụng hàm assign(chỉ định) để cập nhật giá trị của 1 biến với 1 giá trị mới \n",
    "            # khi gọi assigh nó tạo ra một phép toán (operator) mà cần chạy một cách ro ràng để \n",
    "            # cập nhật các biến đó \n",
    "            vr_update = tf.assign(vr, new_vr, use_locking=self._use_locking)\n",
    "            vc_update = tf.assign(vc, new_vc, use_locking=self._use_locking)\n",
    "            updates = [vr_update, vc_update]\n",
    "            # Tính trung bình dài hạn của new_vr \n",
    "            long_term_mean = tf.reduce_mean(new_vr, -1, keepdims=True)\n",
    "            # # Tính nghịc đảo của căn bâc 2 của tỷ lệ giữa new_vr và long_term_mean \n",
    "            # và nghịc đảo của căn bậc 2new_vc \n",
    "            r_factor = tf.rsqrt(new_vr / long_term_mean)\n",
    "            c_factor = tf.rsqrt(new_vc)\n",
    "            # nhân gradient với các yếu tố r_factor và c_factor sau khi mở rộng chiều\n",
    "            x = grad * tf.expand_dims(r_factor, -1) * tf.expand_dims(c_factor, -2)\n",
    "        else:\n",
    "            # trường hợp còn lại \n",
    "            # lấy các slot vr trong biến v\n",
    "            v = self.get_slot(var, \"v\")\n",
    "            # nhân các slot này với tỷ lệ phân dã decay , tỷ lệ trộn , bình phưuowng grad\n",
    "            # để tạo thành v mới \n",
    "            new_v = decay_rate * v + mixing_rate * grad_squared\n",
    "            # sau đó cập nhật v mới cho v \n",
    "            v_update = tf.assign(v, new_v, use_locking=self._use_locking)\n",
    "            # Thêm v đã được vào danh sách chứa các giá trị đã cập nhật \n",
    "            updates = [v_update]\n",
    "            # nhânn grad vơis căn bậc 2 của v mới \n",
    "            x = grad * tf.rsqrt(new_v)\n",
    "        # kiểm tra xem ngưỡng cắt xém = None \n",
    "        if self._clipping_threshold is not None:\n",
    "            # nếu không tính toán một giá trị \n",
    "            clipping_denom = tf.maximum(1.0, reduce_rms(x) / self._clipping_threshold)\n",
    "            # chia x cho giá trị đã được tiunhs toán \n",
    "            x /= clipping_denom\n",
    "\n",
    "        # nhân x với tỷ lệ update_scale \n",
    "        subtrahend = update_scale * x\n",
    "        # kiểm tra xem beta1: a float value between 0 and 1\n",
    "        if self._beta1: \n",
    "            # lấy các slot của m trong var \n",
    "            m = self.get_slot(var, \"m\")\n",
    "            # tạo một gía trị cho m mới \n",
    "            new_m = self._beta1 * tf.to_float(m) + (1.0 - self._beta1) * subtrahend\n",
    "            # gán cho subtrahend = new_m\n",
    "            subtrahend = new_m\n",
    "            # chuyển đổi new_m thành 1 tensor dtype = dtype.var\n",
    "            new_m = cast_like(new_m, var)\n",
    "            # Cập nhật m bằng m mới và thêm vào danh sacchs update \n",
    "            updates.append(tf.assign(m, new_m, use_locking=self._use_locking))\n",
    "        # Thay đổi old val thành kiểu float sau đó trừ subtrahend rồi gán kết quả cho new_val \n",
    "        new_val = tf.to_float(old_val) - subtrahend\n",
    "        # Cập nhật var mới \n",
    "        var_update = tf.assign(var, new_val, use_locking=self._use_locking)\n",
    "        # Thêm giá trị đó vào danh sách update \n",
    "        updates = [var_update] + updates\n",
    "        # Cuối cùng nhóm các tensor var trong update lại với nhau \n",
    "        return tf.group(*updates)\n",
    "\n",
    "    # Xây dựng phương thức định nghĩa độ phân giã mặc định \n",
    "    def _decay_rate_default(self):\n",
    "        return adafactor_decay_rate_pow(0.8)\n",
    "\n",
    "    # Tương tự vơis learning_rate\n",
    "    def _learning_rate_default(self, multiply_by_parameter_scale):\n",
    "        # gán giá trị cho lr\n",
    "        learning_rate = tf.minimum(tf.rsqrt(step_num() + 1.0), 0.01)\n",
    "        # kiểm tra xem có tồn tại một đa sử lý quy mô tham số không \n",
    "        if not multiply_by_parameter_scale:\n",
    "            # nêud có nhân tỷ lẹ lr với 0.05 \n",
    "            learning_rate *= 0.05\n",
    "        return learning_rate\n",
    "\n",
    "\n",
    "# tỷ lệ phân giã cho trình tối ưu hóa adam \n",
    "def adafactor_decay_rate_adam(beta2):\n",
    "    t = tf.to_float(tf.train.get_or_create_global_step()) + 1.0\n",
    "    decay = beta2 * (1.0 - tf.pow(beta2, t - 1.0)) / (1.0 - tf.pow(beta2, t))\n",
    "    # decay = tf.cond(tf.equal(t, 1.0), lambda: beta2, lambda: decay)\n",
    "    return decay\n",
    "\n",
    "# tỷ lệ lũy thừ tham số cho decay \n",
    "def adafactor_decay_rate_pow(exponent):\n",
    "    return 1.0 - tf.pow((step_num() + 1.0), -exponent)\n",
    "\n",
    "# tính toán  tổng các bước \n",
    "def step_num():\n",
    "    return tf.to_float(tf.train.get_or_create_global_step())\n",
    "\n",
    "# Tính mean_squared \n",
    "def reduce_rms(x):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(x)))\n",
    "\n",
    "# Chuyển đổi tensor \n",
    "def cast_like(x, y):\n",
    "    \"\"\"Cast x to y's dtype, if necessary.\"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "\n",
    "    if x.dtype.base_dtype == y.dtype.base_dtype:\n",
    "        return x\n",
    "\n",
    "    cast_x = tf.cast(x, y.dtype)\n",
    "    if cast_x.device != x.device:\n",
    "        x_name = \"(eager Tensor)\"\n",
    "        try:\n",
    "            x_name = x.name\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        tf.logging.warning(\"Cast for %s may induce copy from '%s' to '%s'\", x_name,\n",
    "                        x.device, cast_x.device)\n",
    "    return cast_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [4, 3, 2]  # Kích thước ban đầu của tensor\n",
    "r_val = tf.zeros(shape[:-1], dtype=tf.float32)  # Sẽ tạo một tensor mới với kích thước [4, 3]\n",
    "c_val = tf.zeros(shape[:-2] + shape[-1:], dtype=tf.float32)  # Sẽ tạo một tensor mới với kích thước [4, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_val = tf.zeros(shape[:-2], dtype=tf.float32)\n",
    "e_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
