{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse \n",
    "import json \n",
    "import logging\n",
    "import sys \n",
    "import time \n",
    "from functools import partial \n",
    "from pathlib import Path \n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "import nbimporter\n",
    "import input ; import model_fns ; import predict_fns \n",
    "from inputs import * \n",
    "from model_fns import * \n",
    "from predict_fns import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this program was designed to funcion with multiple kinds of, but currently \n",
    "# but currently, but currently only GPT2 is supported\n",
    "# Trương trình này được thiết kế để hoạt động với nhiều loại mô hình, nhưng hiện tại chỉ hỗ chợ GPT2\n",
    "# phần tử đầu tiên trong tuple là hàm mô hình , phần tử thứ 2 là hàm được gọi ki dự đoán \n",
    "models = {\n",
    "    \"GPT2\": (gpt2_model, gpt2_predict)\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "    \"openwebtext\": openwebtext, # Standard OpenWebtext input\n",
    "    \"openwebtext_longbiased\": openwebtext_longbiased, # OpenWebtext with a bias towards showing more long (>512 tokens) examples\n",
    "    \"openwebtext_long\": openwebtext_long, # Openwebtext that only shows long examples\n",
    "}\n",
    "\n",
    "# sử dụng thư viện argparse để xử lý accs tham số dòng lệnh \n",
    "# argparse tạo một giao diện dòng lệnh cho người dùng nhập các tham số khi chương trình \n",
    "\n",
    "# kiểm tra điều kiện để đảm bảo rằng đoạn mã sẽ chỉ chạy khi tệp tin Python được thực thi như \n",
    "# một chương trình chính , không phải khi nó được nhập như Module \n",
    "if __name__ == \"__main__\":\n",
    "    # tạo một parser mới \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # tHÊM CÁC tham số dòng lệnh \n",
    "    parser.add_argument('--tpu', type=str) # Tên của TPU để huấn luyện , nếu có \n",
    "    parser.add_argument('--model', type=str) # tệp Json chưas các tham số mô hình \n",
    "    parser.add_argument('--predict_text',dtype=str) # lấy chuỗi trực tiếp từ tham số \n",
    "    parser.add_argument('--top_k', type=int) # Tham số cắt giảm top K cho sinh văn bản \n",
    "\n",
    "    # phân tích các tham số được cung cấp \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # khởi tạo biến để kiểm tra chế độ dự đoán \n",
    "    predict_model = False \n",
    "    # Kiểm tra nếu tham số predict_file được  cung cấp \n",
    "    if args.predict_file is not None: \n",
    "        # gán cho biến kiểm tra chế độ dự đoán = True \n",
    "        predict_model = True \n",
    "        # mở tệp predict_file và  gán kết quả cho f \n",
    "        with open(args.predict_file) as f: \n",
    "            # đọc file f và gán kết quả cho biến text \n",
    "            text = f.read()\n",
    "        \n",
    "    # nếu tha số predict_text được cung câos \n",
    "    elif args.predict_text is not None: \n",
    "        # gán predict_model = TREU \n",
    "        predict_model = True \n",
    "        # gán biến text = args.predict_text \n",
    "        text = args.predict_text \n",
    "    # Nếu cả hai tham số predict_file và predict_text đều được cung cấp\n",
    "    elif args.predict_file is not None and args.predict_text is not None:\n",
    "        # In ra lỗi và thoát chương trình\n",
    "        print(\"ERROR: Specify exactly one of --predict_file and --predict_text!\")\n",
    "        sys.exit()\n",
    "    \n",
    "\n",
    "    # Thiết lập ghi nhật ký \n",
    "    # Sử dụng path để tạo một đường dẫn là logs \n",
    "    # và mkdir để tạo thư mục logs tại đường dẫn path \n",
    "    Path('logs').mkdir(exist_ok=True)\n",
    "    # Thiết lập mức độ chi tiết set_verbosity cho việc ghi nhật ký log là Info \n",
    "    tf.logging.set_verbosity(logging.INFO)\n",
    "    # tạo một danh sách các trình xử lý log \n",
    "    handlers = [\n",
    "        # Trình xử lý ghi log vào tệp, đặt tên tệp log dựa trên mô hình \n",
    "        logging.FileHandler(filename='log/{}.log'.format(args.model)),\n",
    "        # Trình xử llys ghi ra stdout (thường là màn hình console)\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    "\n",
    "    # lấy logger của tensorflow \n",
    "    logger = logging.getLogger('tensorflow')\n",
    "    # gán các trình xử lý log đã tạo cho logger \n",
    "    logger.handlers = handlers \n",
    "\n",
    "    # đọc các tham số của mô hình gán\n",
    "    # mở bộ tham số của mô hình args.model gán nó cho f các file này được\n",
    "    # lưu trự dạng tệp json\n",
    "    with open(args.model, \"r\") as f :\n",
    "        # tải các file json từ tệp gán nó cho params \n",
    "        params = json.load(f)\n",
    "\n",
    "    # kiểm tr xem nếu tham số args.tpu tồn tại tức có sử dung \n",
    "    if not args.tpu is None : \n",
    "        # gán cho giá trị use_tpu trong từ điển params = True \n",
    "        params['use_tpu'] = True\n",
    "    # trường hợp còn lại gán = FALSE\n",
    "    else: \n",
    "        params['use_tpu'] = False \n",
    "\n",
    "    # nếu tham số top_k được cung câos \n",
    "    if args.top_k is not None: \n",
    "        # thiết lập nó tring từ điển params \n",
    "        params['top_k'] = args.top_k\n",
    "\n",
    "    # nếu không có khóa percision trong từ điển params \n",
    "    if not 'percision' in params.key():\n",
    "        # thiết lập nó  mặc định là \"float32\"\n",
    "        params[\"precision\"] = \"float32\" # Doesn't actually do anything since \n",
    "        # float32 is the default anyways. Only recognized other dtype is \"bfloat16\"\n",
    "\n",
    "    # Nếu không có khóa \"iterations\" trong params, thiết lập mặc định là 1\n",
    "    if not \"iterations\" in params.keys():\n",
    "        params[\"iterations\"] = 1 # Vì điều này kiểm soát số lượng mẫu được tải trước\n",
    "\n",
    "    # Ghi thông tin của params ra log\n",
    "    logger.info(params)\n",
    "\n",
    "    # Lấy hàm mô hình từ từ điển models dựa trên tên mô hình được cung cấp\n",
    "    # lấy phần tử đầu tiên của danh sách model được trả về bới khóa \n",
    "    # params['model'] trong từ điển model \n",
    "    model_fn = models[params[\"model\"]][0]\n",
    "    # Lấy hàm dự đoán từ từ điển models\n",
    "    # là lấy phần tử số 2 của danh sách model được trả về bới khóa \n",
    "    # params['model'] trong từ điển model \n",
    "    predict_fn = models[params[\"model\"]][1]\n",
    "    # Lấy hàm nhập liệu từ từ điển inputs dựa trên loại đầu vào được cung cấp\n",
    "    input_fn = inputs[params[\"input\"]]\n",
    "\n",
    "\n",
    "    # kiểm tra xem mô hình có đang sử dụng TPU và có đang ở chế độ dự đoán không \n",
    "    if params[\"use_tpu\"] and not predict_model:\n",
    "        # giải quyết cụm TPU và chạy các cấu hình \n",
    "        tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(args.tpu)\n",
    "\n",
    "        # chạy các cấu hình , chuyền vào đó các tham số cần thiếu \n",
    "        # đường danax thư mục , các cụm giải quyết , lưu trữ checkpoint \n",
    "        # và phiên bản cấu hình \n",
    "        run_config = tf.contrib.tpu.RunConfig(\n",
    "            model_dir=params[\"model_path\"],\n",
    "            cluster=tpu_cluster_resolver,\n",
    "            save_checkpoints_secs=60*30,\n",
    "            session_config=tf.ConfigProto(\n",
    "                # allow_soft_placement=True,\n",
    "                # log_device_placement=True\n",
    "                ),\n",
    "                tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=params[\"iterations\"])\n",
    "        )\n",
    "\n",
    "        # Set up network\n",
    "        # Thiết lập Tpu cho mạng \n",
    "        network = tf.contrib.tpu.TPUEstimator(\n",
    "                model_fn=model_fn,\n",
    "                use_tpu=True, # chế độ sử dụng TPU \n",
    "                # kích thước lô đào tạo\n",
    "                train_batch_size=params[\"train_batch_size\"], # These are the global sizes, must be divisible by replicas\n",
    "                # kích thước lô thử nghiệm \n",
    "                eval_batch_size=params[\"eval_batch_size\"],\n",
    "                # kích thước lô cho việc dự đoán\n",
    "                predict_batch_size=params[\"predict_batch_size\"],\n",
    "                config=run_config,\n",
    "                params=params)\n",
    "    \n",
    "    # trường hợp không sử dụng TPU ta thiết lập các tham số \n",
    "    else:\n",
    "        # Non TPU setup\n",
    "        # nếu mô hình không ở chế độ dự đoán\n",
    "        if not predict_model:\n",
    "            # gọi khóa batch_size của từ điển params gán nó = giá \n",
    "            # trị khóa train_batch_size \n",
    "            params[\"batch_size\"] = params[\"train_batch_size\"]\n",
    "        else:\n",
    "            # truuwongf hợp còn lại ta cũng gán tương tự \n",
    "            params[\"batch_size\"] = params[\"predict_batch_size\"]\n",
    "\n",
    "            # gọi phương thức encoder của model.gpt2\n",
    "            from models.gpt2 import encoder\n",
    "            # mã hóa trước đường dẫn thư mục encoder_path được lưu trữ trong từ điển params \n",
    "            # kết quả gán cho biến enc \n",
    "            enc = encoder.get_encoder(params[\"encoder_path\"])\n",
    "            # sử dụng bộ tham số đã học được để mã hóa văn bản cần dự đoán\n",
    "            tokens = enc.encode(text)\n",
    "            # gán cho khóa của text_len trong từ điển params = giá trị len(tokens)\n",
    "            params[\"text_len\"] = len(tokens)\n",
    "            # kiểm tra xem gái trị text len > 1024\n",
    "            if params[\"text_len\"] > 1024:\n",
    "                # nếu có ta gán lại giá trị anyf  = 1024\n",
    "                params[\"text_len\"] = 1024\n",
    "\n",
    "        # chạy các cấu hình \n",
    "        run_config = tf.estimator.RunConfig(\n",
    "            model_dir=params[\"model_path\"],\n",
    "            session_config=tf.ConfigProto(\n",
    "                # log_device_placement=True,\n",
    "                # allow_soft_placement=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # sử dụng Estimator là một API cao cấp trong TensorFlow giúp tạo và quản lý các \n",
    "        # mô hình học máy. Nó xử lý các vòng lặp huấn luyện, đánh giá, và dự đoán, \n",
    "        # giúp việc triển khai mô hình trở nên dễ dàng và hiệu quả hơn. \n",
    "        network = tf.estimator.Estimator(\n",
    "            model_fn=model_fn,\n",
    "            config=run_config,\n",
    "            params=params)\n",
    "        \n",
    "    # nếu mô hình đang ở chế độ dự đoán predict_model = True \n",
    "    if predict_model : \n",
    "        # ghi vào nhật ký log một thông tin quá trình dự đoán đang được tạo ra \n",
    "        logger.info('Generating predictions...')\n",
    "        # truyền các tham số vào predict_fn  để thực hiện dự đoán \n",
    "        # với các tham số cần thiết \n",
    "        predict_fn(network, text, params)\n",
    "        # thoát khỏi chương trình \n",
    "        sys.exit()\n",
    "\n",
    "    # Xây dựng một vòng lặp vô tận sử dụng cho việc train và thẩm định \n",
    "    while True :\n",
    "        # lấy thời gian hiện tại ghi vào biến start \n",
    "        start = time.time()\n",
    "        # huấn luyện mạng sử dụng hàm part ở đây để có thể tái sử dụng giá trị input_fn có sẵn \n",
    "        # cho các mục đích khác tránh viêcj phải viết lại \n",
    "        network.train(\n",
    "                input_fn=partial(input_fn, eval=False),\n",
    "                # số bước đào tạo \n",
    "                steps=params[\"train_steps\"])\n",
    "\n",
    "\n",
    "        # lấy thời gián hiện tại sau ghi huấn luyện xong lưu kết \n",
    "        # quả cho biến end \n",
    "        end = time.time()\n",
    "        # ghi vào log một thông tin thời gian mất để huấn luyện vòng lặp \n",
    "        logger.info(\"\\nTrain loop took {:.2f}s\\n\".format(end-start))\n",
    "\n",
    "        # xác thực dữ liệu evaluate \n",
    "        eval_result = network.evaluate(\n",
    "           input_fn=partial(input_fn, eval=True),\n",
    "           # số bước lặp \n",
    "           steps=params[\"eval_steps\"])\n",
    "\n",
    "        # tương tự như trên ghi nhật ký thông tin \n",
    "        logger.info(\"\\nEval Results: {}\\n\".format(str(eval_result)))\n",
    "\n",
    "        # kiểm tra 1 điều kiện nếu đúng thì thông báo xong và thoát khỏi vòng lặp  \n",
    "        if network.get_variable_value(\"global_step\") > params[\"max_steps\"]:\n",
    "            logger.info(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
