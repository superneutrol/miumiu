{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade keras_cv tensorlfow \n",
    "!pip install --upgrade keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras \n",
    "from keras import osp \n",
    "from keras import layers \n",
    "import tensorflow_datasets as tfds \n",
    "\n",
    "from skimage.data import chelsea \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "    1. `Local-MSA:` Local Multi head Self Attention.\n",
    "    2. `Global-MSA:` Global Multi head Self Attention.\n",
    "    3. `MLP:` Linear layer that projects a vector to another dimension.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng khối tăng cường xử lý cải thiện sức mạnh biểu diễn của mạng noron tích chập \n",
    "# Bằng cách cho phép nó chỉnh lại đặc trưng linh hoạt \n",
    "class SqueezeExcitation(layers.Layer):\n",
    "    \"\"\"    \n",
    "    đầu ra_dim: thứ nguyên của tính năng đầu ra, \n",
    "        nếu `None` sử dụng cùng độ mờ như đầu vào.\n",
    "    mở rộng: tỷ lệ mở rộng.\n",
    "    \"\"\"\n",
    "    # Xây dựng phương thức khởi tạo . Đầu vào của khối này là một khối tích chập \n",
    "    def __init__(self, output_dim=None, expansion=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.expansion = expansion\n",
    "        self.output_dim = output_dim \n",
    "\n",
    "    # Thiết lập 1 phương thức xử lý trong đó ta xây dựng các lớp xử lý cho khối \n",
    "    def build(self, input_shape):\n",
    "        # Gán cho biến inp = kích thước theo chiều cuối cùng của đầu vào \n",
    "        # Đầu vào là đầu ra của một khối tích chập nên chiều cuối cùng sẽ là embed_dim \n",
    "        inp = input_shape[-1]\n",
    "        # Gan kết quả cho biến output_dim = giá trị mặc định hoặc là biến inpt \n",
    "        self.output_dim = self.output_dim or inp \n",
    "        # Đầu tiên thiết lập cho khối nay một lớp gộp trung bình và giữ lại kích thước không gian\n",
    "        self.avg_pool = layers.GlobalAveragePooling2D(keepdims=True , name=\"avg_pool\")\n",
    "        # Sử dụng một mạng noron kết nối đầy đủ để học trọng số cho mỗi kênh \n",
    "        self.fc = [\n",
    "            # Tạo 1 lớp Dense đầu tiên lớp này có chức năng giảm số lượng kênh của hình ảnh\n",
    "            layers.Dense(units= int(inp * self.expansion), use_bias=False , name=\"fc_0\"), \n",
    "            # Add activation funcion\n",
    "            layers.Activation(\"gelu\", name=\"fc_1\"),\n",
    "            layers.Dense(units=self.output_dim , use_bias=False , name=\"fc_2\"),\n",
    "            # Add Activation funcion seconds . \n",
    "            layers.Activation(\"sigmoid\", name=\"fc_3\"),\n",
    "        ]\n",
    "        # Cho phép lớp này có thể kế thừa được \n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Thiết lập phương thức gọi lại để có thể chuyển hóa các lớp xử lý \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Gán cho x = kết quả của lớp gộp trung bình \n",
    "        x = self.avg_pool(inputs)\n",
    "        # Duyệt qua các lớp layer trong khối FC để xử lý chúng \n",
    "        for layer in self.fc: \n",
    "            x = layer(x)\n",
    "        \n",
    "        # Sau đó trả về kết quả là phép nhân của đầu vào và kết quả đầu ra \n",
    "        return x * inputs \n",
    "    \n",
    "\n",
    "# Xây dựng lớp xử lý có chức năng trích xuất các tính năng , Strided Conv để \n",
    "# đồng thời giảm kích thước không gian và tăng độ mờ theo kênh của các tính năng \n",
    "# Cuối cùng là Module layernorma để chuẩn hóa các tính năng \n",
    "\n",
    "class ReduceSize(layers.Layer): \n",
    "    \"\"\"\n",
    "    Khối lấy mẫu xuống.\n",
    "\n",
    "        Lập luận:\n",
    "            keepdims: nếu độ mờ không gian sai giảm và độ mờ kênh tăng\n",
    "    \"\"\"\n",
    "    # Thiết lập phương thức khởi tạo và định nghĩa các tham số cần được xử dụng \n",
    "    def __init__(self, keepdims=False , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.keepdims = keepdims \n",
    "\n",
    "    # Thiết lập phương thức xử lý trong đó xây dựng các lớp , khối xử lý .\n",
    "    def build(self, input_shape):\n",
    "        # Gán biến embed_dim = giá trị inout_shape theo chiều cuối cùng \n",
    "        embed_dim = input_shape[-1]\n",
    "        # Và giá trị của dim_out = embed_dim nếu số chiều biểu diễn (kích thước không gian)\n",
    "        # được giữ lại và 2* embed_dim nếu ngược lại \n",
    "        dim_out = embed_dim if self.keepdims else 2 * embed_dim\n",
    "        # Thiết lập 2 lớp đệm cho hình ảnh để tăng kích thước của đầu vào lên 1 ở mỗi chiều \n",
    "        # Điều này giúp cho đầu ra của các phép tích chập không bị giảm QUÁ NHIỀU \n",
    "        self.pad1 = layers.ZeroPadding2D(padding=1 , name=\"pad1\")\n",
    "        self.pad2 = layers.ZeroPadding2D(padding=1 , name=\"pad2\")\n",
    "\n",
    "        # Tạo một khối tích chập với các lớp xử lý sâu \n",
    "        self.conv = [\n",
    "            # Tạo 1 lớp depthwise để thực hiện các phép tích chập theo chiều sau trên đầu vào \n",
    "            # Đây là một kỹ thuâth để giảm số lượng tham số và tăng hiệu quả tính toán \n",
    "            layers.DepthwiseConv2D(kernel_size=3 , strides=1 , padding=\"valid\",\n",
    "                use_bias=False , name=\"conv_0\"\n",
    "                ),\n",
    "            \n",
    "            # Add Activation funcion gelu \n",
    "            layers.Activation(\"gelu\", name=\"conv_1\"),\n",
    "            # Tiếp theo sử dụng 1 lớp SqueezeAndExtractation để tinh chỉnh lại đặc trưng theo \n",
    "            # theo kênh linh hoạt \n",
    "            SqueezeExcitation(name=\"conv_2\"),\n",
    "\n",
    "            # Cuối cùng ta thêm 1 lớp Tích chập Conv2D thông thường \n",
    "            layers.Conv2D(\n",
    "                embed_dim , kernel_size=1, strides=1 , padding=\"valid\", use_bias=False, name=\"conv_3\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Thiết lập 1 lớp reduce để giảm đi số chiều hình ảnh bằng cách tăng bước nhảy cho của sổ trượt \n",
    "        self.reduction = layers.Conv2D(\n",
    "            dim_out , kernel_size=3 , strides=2 , padding=\"valid\", use_bias=False, name=\"reduction\",\n",
    "        )\n",
    "        # Cuối cùng Thêm vào 2 lớp chuẩn hóa \n",
    "        self.norm1 = layers.LayerNormalization(\n",
    "            -1, 1e-05, name=\"norm1\"\n",
    "        )  # eps like PyTorch\n",
    "        self.norm2 = layers.LayerNormalization(-1, 1e-05, name=\"norm2\")\n",
    "\n",
    "    # Thiêt lập phương thức call để có thể gọi lại các lớp và xử lý \n",
    "    def call (self, inputs , **kwargs):\n",
    "        # Chuẩn hóa đầu vào \n",
    "        x = self.norm1(inputs)\n",
    "        # Thêm đệm cho đầu vào để tăng kích thước số chiều lên 1\n",
    "        xr = self.pad1(x)\n",
    "        # Duyệt qua các lớp layers thuộc khối xử lý lớp \n",
    "        for layer in self.conv : \n",
    "            xr = layer(xr)\n",
    "        \n",
    "        # Cộng kết quả chuẩn hóa ban đầu với kết quả của khối xử lý conv \n",
    "        x = x + xr \n",
    "        # Tiếp tục thêm đêmh để tăng kích thước số chiều lên 1\n",
    "        self.pad2(x)\n",
    "        # giảm bớt số chiều biểu diễn đầu ra \n",
    "        x = self.reduction(x)\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "    \n",
    "# Xây dựng khối MLP là một số xử lý Dày đặc \n",
    "\n",
    "class MLP(layers.Layer):\n",
    "    \"\"\"Multi-Layer Perceptron (MLP) block.\n",
    "\n",
    "    Args:\n",
    "        hidden_features: hidden features dimension.\n",
    "        out_features: output features dimension.\n",
    "        activation: activation function.\n",
    "        dropout: dropout rate.\n",
    "    \"\"\"\n",
    "    # THIÊT LẬP PHƯƠNG THỨC KHỞI TẠO VÀ ĐỊNH NGHĨA CÁC THAM SỐ \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_features=None,\n",
    "        out_features=None,\n",
    "        activation=\"gelu\",\n",
    "        dropout=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "\n",
    "    # xÂY DỤNG MỘT PHƯƠNG THỨC ĐỂ THIẾT LẬP CÁC LỚP XỬ LÝ TRONG ĐO \n",
    "    def build(self, input_shape):\n",
    "        # Gán cho biến in_features là kết quả chiều cuôi cùng của đầu vào \n",
    "        self.in_features = input_shape[-1]\n",
    "        # Tương tự gán kết quar cho hidden_features = in_fearures \n",
    "        self.hidden_features = self.hidden_features or self.in_features\n",
    "        # Một lần nữa tương tự với out_features\n",
    "        self.out_features = self.out_features or self.in_features\n",
    "        # Thiết lập một lớp Dense dày đặc \n",
    "        self.fc1 = layers.Dense(self.hidden_features, name=\"fc1\")\n",
    "        # Thêm hàm kích hoạt xử lý cho lớp\n",
    "        self.act = layers.Activation(self.activation, name=\"act\")\n",
    "        # Tương tự như trên \n",
    "        self.fc2 = layers.Dense(self.out_features, name=\"fc2\")\n",
    "        # Cuối Cuối cùng ta thêm 2 lớp rời bỏ \n",
    "        self.drop1 = layers.Dropout(self.dropout, name=\"drop1\")\n",
    "        self.drop2 = layers.Dropout(self.dropout, name=\"drop2\")\n",
    "    \n",
    "    # Thiết lập phương thức gọi lại các lớp và xử lý trình tự chúng \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Xử lý đầu vào\n",
    "        x = self.fc1(inputs)\n",
    "        # Kích hoạt \n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop2(x)\n",
    "        # Trả về kết quả cuối cùng \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch Embed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchEmbed(layers.Layer):\n",
    "    \"\"\"Patch embedding block.\n",
    "\n",
    "    Args:\n",
    "        embed_dim: feature size dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.pad = layers.ZeroPadding2D(1, name=\"pad\")\n",
    "        self.proj = layers.Conv2D(self.embed_dim, 3, 2, name=\"proj\")\n",
    "        self.conv_down = ReduceSize(keepdims=True, name=\"conv_down\")\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = self.pad(inputs)\n",
    "        x = self.proj(x)\n",
    "        x = self.conv_down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Token Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng một lớp xử lý để trích xuất các đặc trưng từ khối đầu vào tương tự như khối ReduceSize \n",
    "# Nhưng với quy mô thu hẹp hơn \n",
    "\n",
    "class FeatureExtraction(layers.Layer): \n",
    "    \"\"\"Feature extraction block.\n",
    "\n",
    "    Args:\n",
    "        keepdims: bool argument for maintaining the resolution.\n",
    "    \"\"\"\n",
    "    # Thiết lập phương thức khởi tạo và định nghĩa các tham số cần được xử dụng \n",
    "    def __init__(self, keepdims=False , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.keepdims = keepdims \n",
    "\n",
    "    # Thiết lập phương thức xử lý trong đó xây dựng các lớp , khối xử lý .\n",
    "    def build(self, input_shape):\n",
    "        # Gán biến embed_dim = giá trị inout_shape theo chiều cuối cùng \n",
    "        embed_dim = input_shape[-1]\n",
    "        # Và giá trị của dim_out = embed_dim nếu số chiều biểu diễn (kích thước không gian)\n",
    "        # được giữ lại và 2* embed_dim nếu ngược lại \n",
    "        dim_out = embed_dim if self.keepdims else 2 * embed_dim\n",
    "        # Thiết lập 2 lớp đệm cho hình ảnh để tăng kích thước của đầu vào lên 1 ở mỗi chiều \n",
    "        # Điều này giúp cho đầu ra của các phép tích chập không bị giảm QUÁ NHIỀU \n",
    "        self.pad1 = layers.ZeroPadding2D(padding=1 , name=\"pad1\")\n",
    "        self.pad2 = layers.ZeroPadding2D(padding=1 , name=\"pad2\")\n",
    "\n",
    "        # Tạo một khối tích chập với các lớp xử lý sâu \n",
    "        self.conv = [\n",
    "            # Tạo 1 lớp depthwise để thực hiện các phép tích chập theo chiều sau trên đầu vào \n",
    "            # Đây là một kỹ thuâth để giảm số lượng tham số và tăng hiệu quả tính toán \n",
    "            layers.DepthwiseConv2D(kernel_size=3 , strides=1,\n",
    "                use_bias=False , name=\"conv_0\"),\n",
    "            # Add Activation funcion gelu \n",
    "            layers.Activation(\"gelu\", name=\"conv_1\"),\n",
    "            # Tiếp theo sử dụng 1 lớp SqueezeAndExtractation để tinh chỉnh lại đặc trưng theo \n",
    "            # theo kênh linh hoạt \n",
    "            SqueezeExcitation(name=\"conv_2\"),\n",
    "            # Cuối cùng ta thêm 1 lớp Tích chập Conv2D thông thường \n",
    "            layers.Conv2D(\n",
    "                embed_dim , kernel_size=1, strides=1 , use_bias=False, name=\"conv_3\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Kiểm tra xem có phải Chiều không gian biểu diễn ban đầu không được giữ lại hay không \n",
    "        if not self.keepdims: \n",
    "            # Ta sử dụng 1 lớp Gộp giới hạn cho hình ảnh \n",
    "            self.pool = layers.MaxPool2D(3, 2, name=\"pool\")\n",
    "        # Và cuối cùng ta cho phép kế thừa phương thức này\n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Xây dựng phương thức call để gọi lại và xử lý trình tự các lớp \n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        xr = self.pad1(x)\n",
    "        for layer in self.conv:\n",
    "            xr = layer(xr)\n",
    "        x = x + xr\n",
    "        if not self.keepdims:\n",
    "            x = self.pool(self.pad2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Xây dựng lớp mã xử lý có chức năng tạo ra các truy vấn toàn cục cho mô hình \n",
    "# Các truy vấn toàn cục này được sử dụng để thu thập thông tin từ toàn bộ hình ảnh hoặc chuỗi đầu vào \n",
    "# Thay vì tập chung vào một phần nhỏ hoặc một vùng cụ thể \n",
    "\n",
    "# Trong GC ViT các truy vấn toàn cục này có thể giúp mô hình hiểu được bối cảnh rộng lớn hơn và mỗí quan\n",
    "# hệ giữa các phần khác nhau của dữ liệu đầu vào \n",
    "class GlobalQueryGenerator(layers.Layer):\n",
    "    \"\"\"Global query generator.\n",
    "\n",
    "    Args:\n",
    "        keepdims: to keep the dimension of FeatureExtraction layer.\n",
    "        For instance, repeating log(56/7) = 3 blocks, with input\n",
    "        window dimension 56 and output window dimension 7 at down-sampling\n",
    "        ratio 2. Please check Fig.5 of GC ViT paper for details.\n",
    "    \"\"\"\n",
    "    def __init__(self, keepdims=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.keepdims = keepdims\n",
    "\n",
    "    # Thiết lập phương thức Build để tạo 1 danh sách chứa các lớp \n",
    "    # featuresExtract được đặt tên theo chỉ số của chúng và giá trị keepdims\n",
    "    def build (self, input_shape):\n",
    "        # self.to_q_global là danh sách chưa các lớp FeaturesExtract \n",
    "        # mỗi phần tử trong đó đựa Lấy theo chỉ số của keepdims [True, false, True]\n",
    "        # tức là với keepdims thì enumerate sẽ lặp 3 lần \n",
    "        self.to_q_golbal = [\n",
    "            FeatureExtraction(keepdims, name=f\"to_q_global_{i}\")\n",
    "            for i, keepdims in enumerate(self.keepdims)\n",
    "        ]\n",
    "        # Cuối cùng cho nó có thể kế thừa lại phương thức này\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    # Thiết lập phương thức call gọi và xử lý các lớp \n",
    "    def call (self, inputs , **kwargs):\n",
    "        x = inputs \n",
    "        # Duyệtq au danh sách các lớp trong list to_q_global\n",
    "        for layer in self.to_q_golbal:\n",
    "            # Áp dụng mỗi lớp FeaturesExtract lên dữ liệu đầu vào x\n",
    "            x = layer(x)\n",
    "        return x \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng khối Windown Attention đây là một kiến trúc xử lý\n",
    "# của mô hình Swin transformer mục tiêu áp dụng cửa sổ chú ý lên các khung ảnh \n",
    "# Tăng cường mối liên kết các pixel trong hình ảnh cũng như khả năng khái quát hóa mô hình \n",
    "class WindowAttention(layers.Layer):\n",
    "    \"\"\"Local window attention.\n",
    "\n",
    "    This implementation was proposed by\n",
    "    [Liu et al., 2021](https://arxiv.org/abs/2103.14030) in SwinTransformer.\n",
    "\n",
    "    Args:\n",
    "        window_size: window size.\n",
    "        num_heads: number of attention head.\n",
    "        global_query: if the input contains global_query\n",
    "        qkv_bias: bool argument for query, key, value learnable bias.\n",
    "        qk_scale: bool argument to scaling query, key.\n",
    "        attention_dropout: attention dropout rate.\n",
    "        projection_dropout: output dropout rate.\n",
    "    \"\"\"\n",
    "    # Thiết lập phương thức khởi tạo và định nghĩa các tham số cho mô hình \n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size,\n",
    "        num_heads,\n",
    "        global_query,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        attention_dropout=0.0,\n",
    "        projection_dropout=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        # định nghĩa các tham số \n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.global_query = global_query\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.qk_sclae = qk_scale\n",
    "        # Định nghĩa tham số rời bỏ \n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.projection_dropout = projection_dropout\n",
    "\n",
    "    # Thiết lập phương thức Build để xây dựng các lớp cấu trúc xử lý \n",
    "    def build (self, input_shape):\n",
    "        # Lấy ra chiều cuối cùng của tenspr input \n",
    "        embed_dim = input_shape[0][-1] # bỏ đi chiều thứ nhất \n",
    "        # Tính toán số chiều cho mỗi đầu chú ý = embed_dim // num_heads\n",
    "        head_dim = embed_dim // self.num_heads\n",
    "        # Tính toán tham số scale cho attention \n",
    "        self.scale = self.qk_sclae or head_dim**-0.5\n",
    "        # Tính toán qkv size = 3 - self.global_query kết quả là 1 giá trị >= 2 <= 3\n",
    "        # được sử dụng để định danh số lượng vector truy vấn q k v\n",
    "        self.qkv_size = 3 - int(self.global_query)\n",
    "        # Khởi tạo QKV attention bằng một lớp Dense \n",
    "        self.qkv = layers.Dense(units = embed_dim* self.qkv_size,\n",
    "                use_bias= self.qkv_bias , name=\"qkv\")\n",
    "        \n",
    "        # Khởi tạo một bảng vị trí tương đối và các giá trị của nó mục đích của việc này \n",
    "        # cho mỗi cặp cửa sổ trong các phần tử shape = num_window_element , num_heads\n",
    "        self.realtive_position_bias_table = self.add_weight(\n",
    "            name = \"related_position_bias_tabel\",\n",
    "            # shape =  2 chiều cửa sổ * 2 là số lượng phần tử trong 1 hình ảnh \n",
    "            shape = [\n",
    "                (2* self.window_size[0] - 1) * (2 * self.window_size[1] -1),\n",
    "            self.num_heads ,],\n",
    "            # Sau đó khởi tạo các trọng số cho bảng vị trí tươnh đối \n",
    "            # bằng phương pháp khởi tạo trọng số phân phối chuẩn cắt ngọn \n",
    "            # được giới hạn trong một khoảng nhất định\n",
    "            initializer=keras.initializers.TruncatedNormal(stddev=0.2),\n",
    "            # Đặt các tham số của bảng này có thể được cập nhật trong quán trình daod tạo \n",
    "            trainable = True ,\n",
    "            dtype = self.dtype , \n",
    "        )\n",
    "        # Thêm các lớp Xử lý cẩn thiết \n",
    "        self.attn_drop = layers.Dropout(self.attention_dropout, name=\"attn_drop\")\n",
    "        self.proj = layers.Dense(embed_dim, name=\"proj\")\n",
    "        self.proj_drop = layers.Dropout(self.projection_dropout, name=\"proj_drop\")\n",
    "        # Cuối cùng là hàm kích hoạt Activation funcion\n",
    "        self.softmax = layers.Activation(\"softmax\", name=\"softmax\")\n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Thiết lập phương thức Xây dựng vị trí tương đối và giá trị tương ứng \n",
    "    def get_related_position_index(self):\n",
    "        # Lấy ra 2 chiều của cửa sổ \n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        # width \n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        # Xây dựng ma trận có kích thưov h , w \n",
    "        # đặt indexing = ij để mỗi phần tủ trong ma trận là duy nhất\n",
    "        coords_matrix = np.meshgrid(coords_h , coords_w , indexing='ij')\n",
    "        # Xây dựng tensor corrd bằng cách xếp chồng 2 ma trận coords lên nhau \n",
    "        # kết quả là 1 tensor shape = [2 , w , h]\n",
    "        coords = np.stack(coords_matrix)\n",
    "        # sau đó làm phẳng lại tensor này với shape [2 , -1] với tham số \n",
    "        # - 1 có nghĩa là ở đây tự tính = num_element \n",
    "        coords_flatten = coords.reshape(coords ,[2 -1])\n",
    "        # Xây dựng ma trận relative_coords  bằng cách thêm chiều cho ma trận flattent\n",
    "        # sau đó thực hiện phép trừ để có được ma trận relative_coords \n",
    "        # shape = [2, num_window_elements, num_window_elements] \n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :,]\n",
    "        # Sau đó chuyển vị các chiều của ma trận này cho nhau [1 , 2 ,0]\n",
    "        # shape = [num_element , num_element , 2] chiều cuối cùng cho biết khoảng cách vị trí \n",
    "        # hàng và cột \n",
    "        relative_coords = relative_coords.transpose([1 , 2 , 0])\n",
    "        # Cộng các chỉ số hàng và cột của ma trận với 1 hằng số duy nhất \n",
    "        relative_coords_xx = relative_coords[:, :, 0] + self.window_size[0] - 1\n",
    "        relative_coords_yy = relative_coords[:, :, 1] + self.window_size[1] - 1\n",
    "        # Sau đó ta nhân tọa độ x tương đối của ma trận với hằng số để chuyển đổi tọa độ x tương đối\n",
    "        # thành một giá trị có thêt kết hợp với toạn độ y tương đối \n",
    "        # để tạo ra một chỉ số duy nhất cho mỗi vị trí \n",
    "        relative_coords_xx = relative_coords_xx * (2 * self.window_size[1] - 1)\n",
    "        # Cuối cùng cộng tọa độ x và y tương đối đã được chỉnh để tạo một chỉ số vị trí tương đối duy nhất \n",
    "        # cho mỗi điểm trong cửa sổ \n",
    "        relative_position_index = relative_coords_xx + relative_coords_yy \n",
    "        # Cuối cùng trả về ma trận vị trí tương đối \n",
    "        return relative_position_index # shape = [num_elemnet , num_element]\n",
    "    \n",
    "    # Xây dựng phương thức tính toán Attention , ma trận possition bias\n",
    "    def call (self, inputs, **kwargs):\n",
    "        # kiểm tra xem giá trị Golobal_query có tồn tại\n",
    "        if self.global_query:\n",
    "            # gán giá trị 2 biến inputs và q_global = Inputs \n",
    "            # input là 1 tensor shape [batch_size , h*w , c]\n",
    "            inputs , q_global = inputs \n",
    "            # Lấy ra kích thước Lô batch_size \n",
    "            B = tf.shape(q_global)[0]\n",
    "        # Trường hợp còn lại \n",
    "        else : \n",
    "            # Gán cho inputs = batch_size \n",
    "            inputs = inputs[0]\n",
    "        \n",
    "        # Lấy ra kích thước của tensor đầu vào shape = [batch_size * Num_window , num_tokens , channels]\n",
    "            # Note channel trong swin transformer = embedim \n",
    "        B_, N , C = inputs.shape \n",
    "        # Tạo tensor QKV shape = [Batch_size , num_heads ,size ,3 * head_dim]\n",
    "        qkv = self.qkv(inputs)\n",
    "        # Định hình lại tensor với shape  =[B_, size, self.qkv_size(3), self.num_heads, C // self.num_heads]\n",
    "        qkv = tf.reshape(\n",
    "            qkv, [B_, N, self.qkv_size, self.num_heads, C // self.num_heads]\n",
    "        )\n",
    "        # Chuyển vị tensor qkv thành hình dạng shape = [3 , batch_size , num_heads ,size , embed_dim ] \n",
    "        # mục đích để có thể tách chiều tensor qkv thành các tensor riêng lẻ \n",
    "        qkv = tf.transpose(qkv, [2, 0, 3, 1, 4])\n",
    "        # Kiểm tra xem giá trị biếnn global_query có tồn tại không \n",
    "        if self.global_query:\n",
    "            # Nếu có tách 2 tensor q và k từ tensor qkv thành 2 phần theo chiều đầu tiên \n",
    "            k, v = tf.split(\n",
    "                qkv, indices_or_sections=2, axis=0\n",
    "            )  # for unknown shame num=None will throw error\n",
    "\n",
    "            # Lặp lại q_global (là giá trị đầu vào với số lần bằng với số lượng cửa sổ) để mỗi cứa sổ \n",
    "            # trên 1 hình ảnh có cùng một bản sao của gLOBAL .\n",
    "            q_global = tf.repeat(\n",
    "                q_global, repeats=B_ // B, axis=0\n",
    "            )  # num_windows = B_//B => q_global same for all windows in a img\n",
    "\n",
    "            # Định hình lại kích thước tensor q = [Num_window , size , num_head , embed_dim]\n",
    "            q = tf.reshape(\n",
    "                q_global, new_shape=[B_, N, self.num_heads, C // self.num_heads]\n",
    "            )\n",
    "            q = tf.transpose(q, axes=[0, 2, 1, 3])\n",
    "        else:\n",
    "            # Tách qkv thành 3 vectoe riêng biệt chia làm 3 phần theo chiều đầu tiên \n",
    "            q, k, v = tf.split(qkv, indices_or_sections=3, axis=0)\n",
    "            # Xóa bỏ đi chiều kích thước = 1 axis= 0 nếu chiều đầu = 1 sẽ loại bỏ \n",
    "            q = tf.squeeze(q, axis=0)\n",
    "\n",
    "        # Tuowng tự như tensor k và v\n",
    "        k = tf.squeeze(k, axis=0)\n",
    "        v = tf.squeeze(v, axis=0)\n",
    "\n",
    "        # Nhân Vector q với 1 tham số tỷ lệ scale \n",
    "        q = q * self.scale\n",
    "        # Tính toán attention q*K.T kết quả 1 tensor mới shape = [batch_size ,  num_heads , size ,size]\n",
    "        # là kết quả sau khi @ K.T shape = [batch_size , num_head ,head_dim , size]\n",
    "        attn = q@ tf.transpose(k , perm=[0, 1, 3 ,2])\n",
    "        # Tinhs toans ma trận bias vị trí tương đối \n",
    "        # Sử dụng tf.gather để trích xuất hình dạng cho ma trận relative_position_bias \n",
    "        # Nhằm mục đích lấy các giá trị từ ma trận relative_position_bias_tabel theo chỉ số của ma trận relative_position_index \n",
    "        relative_position_bias = tf.gather(\n",
    "            self.realtive_position_bias_table,\n",
    "            # Thay đổi hình dạng của ma trận relative_position_index thành ma trận 1 chiều \n",
    "            # với số lượng các tham số tự tính \n",
    "            tf.reshape(self.get_relative_position_index(), new_shape=[-1]),\n",
    "        ) # shape = [num_heads , num_window_element * num_window_elemnet]\n",
    "\n",
    "        # Sau đó ta resahpe lại tensor relative_position_bias shape = [ num_window_element , num_window_element , num_head]\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias , \n",
    "            shape = [\n",
    "                # shape = [ num_window_element , num_window_element , num_head]\n",
    "                self.window_size[0] * self.window_size[1],\n",
    "                self.window_size[0] *  self.window_size[1],\n",
    "                -1\n",
    "            ],\n",
    "        )\n",
    "        # Sau đó đảo chiều ma trận này \n",
    "        relative_position_bias = tf.transpose(relative_position_bias , perm=(2 ,0 ,1))\n",
    "        # Rồi cộng ma trận Attention với am trận này để thêm bias cho vị trí tương đối \n",
    "        # trong cửa sổ chú ý  // 2 ma trận này có cùng kích thước nên S sẽ có dạng [batch_size , num_heads, size , size]\n",
    "        attn = attn + relative_position_bias[None,]\n",
    "        # Chuyển đến hàm softmax \n",
    "        attn = self.softmax(attn)\n",
    "        # Qua 1 lớp tách rơi dropout \n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # Tính điểm socre cho attention shap = [ batch_size , num_heads , size , head_dim]\n",
    "        x_qkv = attn @ v\n",
    "        # Hoán vị các chiều của x_qkv để có dạng (batch_size, size, num_heads, head_dim)\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        # Thay đổi hình dạng của x_qkv thành (batch_size, size, channels), \n",
    "        # để nối các đầu chú ý lại với nhau theo chiều thứ 3 \n",
    "        x_qkv = tf.reshape(x_qkv, shape=(B_, N , C))\n",
    "        # áp dụng lớp dense để biến đổi về 1 tensor có kích thước ban đầu và 1 lớp bỏ học \n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        # Nhúng tuyến tính và qua 1 lớp tách rời \n",
    "        x_qkv = self.proj_drop(self.proj(x_qkv))\n",
    "        return x_qkv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng hàm Dropath để loại bỏ ngẫu nhiên cho một tensor đầu vào \n",
    "layers.Dropout(0.1) \n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob \n",
    "\n",
    "    def call(self, x):\n",
    "        # lấy ra kích thước của tensor đầu vào x \n",
    "        input_shape = tf.shape(x)\n",
    "        # lấy ra kích thước lô \n",
    "        batch_size = input_shape[0]\n",
    "        # lấy ra số chiều của x bằng hàm rank \n",
    "        rank = x.shape.rank #  = 4 shape x [batch_size , window_size , widow_size , channels]\n",
    "        # tạo 1 biến shape có shape = batch_size , 1 , 1 ,1 \n",
    "        # đầu tiên ta tạo ma biến typle với batch_size phàn tử là chiều đầu tiên của shape \n",
    "        # sau đó ta tính toán số chiều còn lại  = 1 *(rank-1) tức là 3 chiều \n",
    "        # với shape 3 chiều  = 1 \n",
    "        shape = ( batch_size,) + (1,) * (rank-1) # shape = [batch_size , 1 , 1 ,1]\n",
    "        # sau đó tạo 1 tensor ngẫu nhiên = xác xuất 1 - drop_prob  + shape \n",
    "        # mục đích tạo ra 1 tensor với các phần tử đc lấy ngẫu nhiên [0 -> 1]\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape , dtype=x.dtype)\n",
    "        # Xây dựng một ma trận Path_mask bằng cách làm tròn xuống các tỷ lệ của tensor \n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        # sau đó tính đầu ra bằng thực hiện chia cho tỷ lệ 1 - drop_prob rồi nhân với ma trận \n",
    "        # tỷ lệ path_mask \n",
    "        output = tf.math.divide(x , 1 - self.drop_prob) * path_mask\n",
    "        return output \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(layers.Layer):\n",
    "    \"\"\"\"\n",
    "        GCVIT block. \n",
    "\n",
    "        Args : \n",
    "            window_size : window_size . \n",
    "            num_heads : number of attention head \n",
    "            global_query : apply global window attention\n",
    "            mlp_rotio : MLP rotio\n",
    "            qkv_bias: bool argument for query, key, value learnable bias.\n",
    "            qk_scale: bool argument to scaling query, key.\n",
    "            drop: dropout rate.\n",
    "            attention_dropout: attention dropout rate.\n",
    "            path_drop: drop path rate.\n",
    "            activation: activation function.\n",
    "            layer_scale: layer scaling coefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    # Thiiết lập phương thức khởi tạo và định nghĩa các tham số \n",
    "    def __init__(\n",
    "        self, window_size, num_heads,\n",
    "        global_query, mlp_ratio=4.0, qkv_bias=True,\n",
    "        qk_scale=None, dropout=0.0, attention_dropout=0.0,\n",
    "        path_drop=0.0, activation=\"gelu\", layer_scale=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.global_query = global_query\n",
    "        self.mlp_rotio = mlp_ratio\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.qk_scale = qk_scale\n",
    "        self.dropout = dropout\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.path_drop = path_drop\n",
    "        self.activation = activation\n",
    "        self.layer_scale = layer_scale\n",
    "\n",
    "    # Xây dựng khối xử lý các lớp chức năng \n",
    "    def build (self, input_shape):\n",
    "        # Lấy ra các kích thước của tensor đầu vào '\n",
    "        B , H , W , C = input_shape[0]\n",
    "        # Xây dựng 2 lớp chuẩn hóa layernormal \n",
    "        self.norm1 = layers.LayerNormalization(-1 , 1e-05, name=\"norm1\")\n",
    "        # Xây dựng Cửa sổ chú Ý Windown Attention \n",
    "        self.attn = WindowAttention(\n",
    "            window_size= self.window_size,\n",
    "            num_heads=self.num_heads,\n",
    "            global_query=self.global_query,\n",
    "            qkv_bias=self.qkv_bias,\n",
    "            qk_scale=self.qk_scale,\n",
    "            attention_dropout=self.attention_dropout,\n",
    "            projection_dropout=self.dropout,\n",
    "            name=\"attn\",\n",
    "        )\n",
    "        # Sau đó xây dựng 2 lớp tách rời dropout_path  \n",
    "        self.drop_path1 = DropPath(self.path_drop)\n",
    "        self.drop_path2 = DropPath(self.path_drop)\n",
    "        self.norm2 = layers.LayerNormalization(-1 , 1e-05, name=\"norm1\")\n",
    "\n",
    "        # Xây dựng khối xử lý MLP \n",
    "        self.mlp = MLP(\n",
    "            hidden_features=int(C * self.mlp_rotio),\n",
    "            dropout= self.dropout, \n",
    "            activation= self.activation, name=\"mlp\",\n",
    "        )\n",
    "        # Kiểm tra xem giá trị self.layer_scale có tồn tại hay không \n",
    "        if self.layer_scale is not None: \n",
    "            # Nếu tồn tại định nghĩa 2 biến gamma là một vector biểu diễn các trọng \n",
    "            # số được khởi tạo với tỷ lệ self.layer_scale \n",
    "            self.gamma1 = self.add_weight(\n",
    "                name=\"gamma1\", shape= [C],\n",
    "                initializer= keras.initializers.Constant(self.layer_scale),\n",
    "                # đặt các tham số này có thể được cập nhật khi huấn luyện\n",
    "                trainable = True , dtype = self.dtype , \n",
    "            )\n",
    "            # Tương tự định nghĩa thêm giá trị gamma2 \n",
    "            self.gamma2 = self.add_weight(\n",
    "                name=\"gamma2\",\n",
    "                shape=[C],\n",
    "                initializer=keras.initializers.Constant(self.layer_scale),\n",
    "                trainable=True,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        # Trường hợp còn lại tức không tồn tại giá trị layer_scale \n",
    "        else:\n",
    "            # Gán trực tiếp gamma1 và gamma2 = 1.0 \n",
    "            self.gamma1 = 1.0\n",
    "            self.gamma2 = 1.0\n",
    "        # Tiếp theo ta tính toán số lượng cửa sổ trên 1 hình ảnh \n",
    "        # Bằng cách nhân thương của 2 chiều H và W của hình ảnh với kích thước của cửa sổ cho nhau \n",
    "        self.num_windows = int(H // self.window_size) * int(W // self.window_size)\n",
    "        # Cuối cùng ta đặt phương thức Build này ở chế độ kế thừa để có thể tái sử dụng \n",
    "        # lại các cấu trúc \n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Thiết lập phương thức call để thực hiện xử lý các lớp cấu trúc trong khối \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Đầu tiên kiểm tra xem giá trị global_Quẻy \n",
    "        if self.global_query:\n",
    "            # Gán giá trị cho 2 biến inputs và q_global = inputs (là 1 tuples gồm 2 phần tử)\n",
    "            inputs , q_global = inputs \n",
    "        # else inputs = inputs [0]\n",
    "        else:\n",
    "            inputs = inputs[0]\n",
    "        B, H, W, C = tf.shape(inputs)\n",
    "        x = self.norm1(inputs)\n",
    "        # create windows and concat them in batch axis\n",
    "        x = self.window_partition(x, self.window_size)  # (B_, win_h, win_w, C)\n",
    "        # flatten patch\n",
    "        x = tf.reshape(x, new_shape=[-1, self.window_size * self.window_size, C])\n",
    "        # attention\n",
    "        if self.global_query:\n",
    "            x = self.attn([x, q_global])\n",
    "        else:\n",
    "            x = self.attn([x])\n",
    "        # reverse window partition\n",
    "        x = self.window_reverse(x, self.window_size, H, W, C)\n",
    "        # FFN\n",
    "        x = inputs + self.drop_path1(x * self.gamma1)\n",
    "        x = x + self.drop_path2(self.gamma2 * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "    \n",
    "    # Xây dựng phương thức xử lý tạo vách ngăn cửa sổ WIndow Attention \n",
    "    def window_partition(self, x, window_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, H, W, C)\n",
    "            window_size: window size\n",
    "        Returns:\n",
    "            local window features (num_windows*B, window_size, window_size, C)\n",
    "        \"\"\"\n",
    "        # Lấy ra kích thước của tensor đầu vào [batch_size, h , w , channels]\n",
    "        B, H, W, C = tf.shape(x)\n",
    "        # Reshape lại x thành hình dạng [-1 , patch_num_H , window_size,\n",
    "        # patch_num_W , window_size , Channle] với tham số  -1 \n",
    "        # là số lượng hình ảnh trên 1 cửa sổ \n",
    "        x = tf.reshape(\n",
    "            x,\n",
    "            new_shape=[\n",
    "                -1,\n",
    "                H // window_size, # số lượng ảnh theo chiều dọc\n",
    "                window_size, \n",
    "                W // window_size, # Số lượng ảnh theo chiều ngang \n",
    "                window_size,\n",
    "                C,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Reshape lại hình dạng của tensor shape = [-1 , patch_num_y , patch_num_x , window_size , window_size , channels]\n",
    "        x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
    "        # Định dạng lại kích thước của cửa sổ và trả nó về shape \n",
    "        # = [-1 window_size , window_size, Channel] -1 là số lượng cửa sổ\n",
    "        windows = tf.reshape(x, new_shape=[-1, window_size, window_size, C])\n",
    "        # Trả về kết quả là mộ tensor chứa số lượng cửa sổ kích thước và kênh màu \n",
    "        return windows\n",
    "    # Xây dượng phương thức cứa ổ chuyển đổi phương thức này sẽ thược hiện ngược lại \n",
    "    # so với phương thức trên \n",
    "    def window_reverse(self, windows, window_size, H, W, C):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            windows: local window features (num_windows*B, window_size, window_size, C)\n",
    "            window_size: Window size\n",
    "            H: Height of image\n",
    "            W: Width of image\n",
    "            C: Channel of image\n",
    "        Returns:\n",
    "            x: (B, H, W, C)\n",
    "        \"\"\"\n",
    "        # Định dạng lại x về dạng [-1 ,num_patch_H , num_patch_W ,size , size ,channels ]\n",
    "        x = tf.reshape(\n",
    "            windows,\n",
    "            new_shape=[\n",
    "                -1,\n",
    "                H // window_size, # Tính toán num_patch H\n",
    "                W // window_size, # Tính toán num_batch w\n",
    "                window_size,\n",
    "                window_size,\n",
    "                C,\n",
    "            ],\n",
    "        )\n",
    "        # chuyển đổi tensor về shape = [number , patch_num_y , patch_num_x , size_window , size_window ,c]\n",
    "        x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
    "        # định hình lại kích thước cho x với -  1 là tham số tự tính cho phù hợp \n",
    "        # với bước tính toán để có được số lượng cửa sổ phù hợp \n",
    "        x = tf.reshape(x, new_shape=[-1, H, W, C])\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng lớp Leval để xử lý các tác vụ liên quan đến cấu hình accs tham số .. trong GCViT \n",
    "class Level(layers.Layer):\n",
    "    \"\"\"GCViT level.\n",
    "\n",
    "    Args:\n",
    "        depth: number of layers in each stage.\n",
    "        num_heads: number of heads in each stage.\n",
    "        window_size: window size in each stage.\n",
    "        keepdims: dims to keep in FeatureExtraction.\n",
    "        downsample: bool argument for down-sampling.\n",
    "        mlp_ratio: MLP ratio.\n",
    "        qkv_bias: bool argument for query, key, value learnable bias.\n",
    "        qk_scale: bool argument to scaling query, key.\n",
    "        drop: dropout rate.\n",
    "        attention_dropout: attention dropout rate.\n",
    "        path_drop: drop path rate.\n",
    "        layer_scale: layer scaling coefficient.\n",
    "    \"\"\"\n",
    "    # Xây dựng phương thức khởi tạo và định ghĩa các tham số \n",
    "    def __init__(\n",
    "        self, depth,  num_heads,\n",
    "        window_size,  keepdims,\n",
    "        downsample=True,  mlp_ratio=4.0,\n",
    "        qkv_bias=True, qk_scale=None,\n",
    "        dropout=0.0,  attention_dropout=0.0,\n",
    "        path_drop=0.0, layer_scale=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Định nghĩa các tham số \n",
    "        super().__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.keepdims = keepdims\n",
    "        self.downsample = downsample\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.qk_scale = qk_scale\n",
    "        self.dropout = dropout\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.path_drop = path_drop\n",
    "        self.layer_scale = layer_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # kiểm tra xem pathdrop có phải 1 dnah sách hay không . Nếu không nó sẽ tạo một danh sách mới với \n",
    "        # Phần tử duy nhất là self.path_drop và nhân lặp nó với self.depth lần \n",
    "        path_drop = (\n",
    "            # [self.path_drop] tạo 1 danh sách mới với 1 phần tử duy nhất là giá trị của self.path_drop \n",
    "            [self.path_drop] * self.depth # Nhân lặp danh sách với self.depth lần để tạo 1 danh sách mới với depth phần tử \n",
    "            # kiểm tra xem self.path drop có phải 1 danh sách list \n",
    "            if not isinstance(self.path_drop, list)\n",
    "            # Nếu nó đã là 1 danh scahs list đoạn mã sẽ không thực thi gì và giữ nguyên giá trị của self.path_drop \n",
    "            else self.path_drop\n",
    "        )\n",
    "        # Gọi đến lớp xử lý Windown attention là kiến trúc cốt lõi của mô hình \n",
    "        self.blocks = [\n",
    "            Block(\n",
    "                # Truyền vào khôi block các tham số \n",
    "                window_size=self.window_size,\n",
    "                num_heads=self.num_heads,\n",
    "                global_query=bool(i % 2),\n",
    "                mlp_ratio=self.mlp_ratio,\n",
    "                qkv_bias=self.qkv_bias,\n",
    "                qk_scale=self.qk_scale,\n",
    "                dropout=self.dropout,\n",
    "                attention_dropout=self.attention_dropout,\n",
    "                path_drop=path_drop[i],\n",
    "                layer_scale=self.layer_scale,\n",
    "                name=f\"blocks_{i}\",\n",
    "            )\n",
    "            for i in range(self.depth)\n",
    "        ]\n",
    "        # Giảm số chiều không gia mẫu \n",
    "        self.down = ReduceSize(keepdims=False, name=\"downsample\")\n",
    "        # thực hiện truy vấn toàn cục để tăng cường khả năng biểu diễn không gian mẫu \n",
    "        self.q_global_gen = GlobalQueryGenerator(self.keepdims, name=\"q_global_gen\")\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        q_global = self.q_global_gen(x)  # shape: (B, win_size, win_size, C)\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            if i % 2:\n",
    "                x = blk([x, q_global])  # shape: (B, H, W, C)\n",
    "            else:\n",
    "                x = blk([x])  # shape: (B, H, W, C)\n",
    "        if self.downsample:\n",
    "            x = self.down(x)  # shape: (B, H//2, W//2, 2*C)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCViT(keras.Model):\n",
    "    \"\"\"\"\n",
    "        GCViT model. \n",
    "\n",
    "    Args: \n",
    "        window_size : window size in each stage.\n",
    "        embed_dim: feature size dimension.\n",
    "        depths: number of layers in each stage.\n",
    "        num_heads: number of heads in each stage.\n",
    "        drop_rate: dropout rate.\n",
    "        mlp_ratio: MLP ratio.\n",
    "        qkv_bias: bool argument for query, key, value learnable bias.\n",
    "        qk_scale: bool argument to scaling query, key.\n",
    "        attention_dropout: attention dropout rate.\n",
    "        path_drop: drop path rate.\n",
    "        layer_scale: layer scaling coefficient.\n",
    "        num_classes: number of classes.\n",
    "        head_activation: activation function for head.\n",
    "    \"\"\"\n",
    "    # Thiết lập phương thức khởi tạo và định nghĩa các tham số \n",
    "    def __init__(\n",
    "        self, window_size, embed_dim, depths, num_heads,\n",
    "        drop_rate=0.0, mlp_ratio=3.0, qkv_bias=True,\n",
    "        qk_scale=None, attention_dropout=0.0, path_drop=0.1,\n",
    "        layer_scale=None, num_classes=1000, head_activation=\"softmax\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Định nghĩa các tham số \n",
    "        super().__init__(**kwargs)\n",
    "        self.window_size = window_size # kích thước cửa sổ\n",
    "        self.embed_dim = embed_dim # Kích thước nhúng\n",
    "        self.depths = depths # số lớp layer\n",
    "        self.num_heads = num_heads # Đầu chú ý\n",
    "        self.drop_rate = drop_rate # dropout_rate \n",
    "        self.mlp_ratio = mlp_ratio # MLP \n",
    "        self.qkv_bias = qkv_bias # QKV USE BIAS\n",
    "        self.qk_scale = qk_scale # SCALE FOR QKV ATTENTION\n",
    "        self.attention_dropout = attention_dropout # Attention dropout \n",
    "        self.path_drop = path_drop\n",
    "        self.layer_scale = layer_scale\n",
    "        self.num_classes = num_classes \n",
    "        self.head_activation = head_activation\n",
    "\n",
    "        # Nhúng các bản vá hình ảnh \n",
    "        self.patch_embed = PatchEmbed(embed_dim=embed_dim, name=\"patch_embed\")\n",
    "        self.pos_drop = layers.Dropout(drop_rate, name=\"pos_drop\")\n",
    "        # tạo một mảng numpy path_drop gia giátrij [0.0 -> path_drop] số lượng phần tử \n",
    "        # = tổng các phần tử của mảng depths \n",
    "        path_drops = np.linspace(0.0 , path_drops, sum(depths))\n",
    "        # và danh sách tham số keepdims = các giá trị 0 , 1 true or false\n",
    "        keepdims = [(0, 0, 0), (0, 0), (1,), (1,)]\n",
    "        # Khơỉ tạo một danh sách levels = []\n",
    "        #  sẽ được điền bằng các đối tượng GCBlock, là các khối tự chú ý toàn cục và cục bộ.\n",
    "        self.levels = []\n",
    "        # Duyệt qua 1 danh sách các phần tử 0 -> độ dài danh sách depths \n",
    "        for i in range (len(depths)):\n",
    "            # Gán giá trị cho biến path_drop bằng độ dài 1 đoạn của mảng path_drop tương ứng \n",
    "            # với mỗi mức sau đó sử dụng tolist để chuyển thành 1 danh sách\n",
    "            # và sử dụng nó để khởi tạo một đối tượng GCBlock \n",
    "            path_drop = path_drops[sum(depths[:i])  : sum(depths[: i + 1])].tolist()\n",
    "            # Và sử dụng để tạo đối tượng GCBlock \n",
    "            level = Level(\n",
    "                depth=depths[i],\n",
    "                num_heads=num_heads[i],\n",
    "                window_size=window_size[i],\n",
    "                keepdims=keepdims[i],\n",
    "                downsample=(i < len(depths) - 1),\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                qk_scale=qk_scale,\n",
    "                dropout=drop_rate,\n",
    "                attention_dropout=attention_dropout,\n",
    "                path_drop=path_drop,\n",
    "                layer_scale=layer_scale,\n",
    "                name=f\"levels_{i}\",\n",
    "            )\n",
    "            # thêm nó vào danh sách self.levels \n",
    "            self.levels.append(level)\n",
    "        # Thực hiện chuẩn hóa đầu ra \n",
    "        self.norm = layers.LayerNormalization(axis=-1 , epsilon=1e-5, name=\"norm\")\n",
    "        # chuyển qua 1 lớp gộp trung bình  và cuối cùng la 1 lớp dày đặc \n",
    "        self.pool = layers.GlobalAvgPool2D(name=\"pool\")\n",
    "        self.head = layers.Dense(num_classes, name=\"head\", activation=head_activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.built = True\n",
    "\n",
    "    # Thiết lập phương thức call để gọi lại các lớp xử lý và thực hiện tiến trình xử lý \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # nhúng hình ảnh \n",
    "        x = self.patch_embed(inputs)\n",
    "        # Chuyển qua 1 lớp tách rời\n",
    "        x = self.pos_drop(x)\n",
    "        # Duyệt qua danh sách các đối tượng trong danh scahs level \n",
    "        for level in self.levels:\n",
    "            # áp dụng khối xử lý swin lên đầu vào x\n",
    "            x = level(x)  # shape: (B, H_, W_, C_)\n",
    "        # thực hiện chuẩn hóa \n",
    "        x = self.norm(x)\n",
    "        x = self.pool(x)  # shape: (B, C__)\n",
    "        # cuối cùng là lớp phân loại \n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    # Xây dựng kiến trúc mô hình \n",
    "    def build_graph(self, input_shape=(224, 224, 3)):\n",
    "        \"\"\"\n",
    "        ref: https://www.kaggle.com/code/ipythonx/tf-hybrid-efficientnet-swin-transformer-gradcam\n",
    "        \"\"\"\n",
    "        # Thiết lập lớp đầu vào \n",
    "        x = keras.Input(shape=input_shape)\n",
    "        # Thiết lập mô hình GCVit \n",
    "        return keras.Model(inputs=[x], outputs=self.call(x), name=self.name)\n",
    "\n",
    "    # Tóm tắt kiến trúc mô hình và tham số tôngt quát \n",
    "    def summary(self, input_shape=(224, 224, 3)):\n",
    "        return self.build_graph(input_shape).summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configs\n",
    "config = {\n",
    "    \"window_size\": (7, 7, 14, 7),\n",
    "    \"embed_dim\": 64,\n",
    "    \"depths\": (2, 2, 6, 2),\n",
    "    \"num_heads\": (2, 4, 8, 16),\n",
    "    \"mlp_ratio\": 3.0,\n",
    "    \"path_drop\": 0.2,\n",
    "}\n",
    "ckpt_link = (\n",
    "    \"https://github.com/awsaf49/gcvit-tf/releases/download/v1.1.6/gcvitxxtiny.keras\"\n",
    ")\n",
    "\n",
    "# Build Model chuyền tham số cấu hình qua giá trị kwargs \n",
    "model = GCViT(**config)\n",
    "# Định cấu hình co ảnh đầu vào shape 244 * 244 * 3 \n",
    "inp = np.array(np.random.uniform(size=(1, 224, 224, 3)))\n",
    "out = model(inp)\n",
    "\n",
    "# Load Weights Tải trọng số của mô hình đã đựoc đào tạo trước \n",
    "ckpt_path = keras.utils.get_file(ckpt_link.split(\"/\")[-1], ckpt_link)\n",
    "model.load_weights(ckpt_path)\n",
    "\n",
    "# Summary \n",
    "model.summary((224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check for Pre-Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập phương thức tiền xử lý hình ảnh trong keras với tập dữ liệu chelsea \n",
    "img = keras.applications.imagenet_utils.preprocess_input(\n",
    "    chelsea() , mode = \"torch\"\n",
    ") # Chelsea the cat \n",
    "# Resize hình ảnh về dạng tiêu chuẩn 224 * 224 * 3 và khởi tạo các batch\n",
    "img = tf.image.resize(img , (224, 224))[None, ]\n",
    "# Thử nghiệm mô hình với tiền đào tạo trước hình ảnh và dự đoán hình ảnh \n",
    "pred = model(img)\n",
    "# Lấy ra xác xuất dự đoán cho hình ảnh \n",
    "pred_dec = keras.applications.imagenet_utils.decode_predictions(pred)[0]\n",
    "\n",
    "# Hiển thị hình ảnh và in ra các thông số dự đoán cho mô hình \n",
    "print(\"\\n# Image:\")\n",
    "# Định cấu hình khung hiển thị hình ảnh 6 *6  inch \n",
    "plt.figure(figsize=(6, 6))\n",
    "# Sử dụng plt.imshow để hiển thị ra hình ảnh\n",
    "plt.imshow(chelsea())\n",
    "plt.show()\n",
    "\n",
    "# In ra Top 5 phân loại cho hình ảnh có xác xuất cao nhất \n",
    "print(\"# Prediction (Top 5)\")\n",
    "for i in range(5):\n",
    "    print (\"{:<12} : {:0.2f}\").format(pred_dec[i][1], pred_dec[i][2])\n",
    "\n",
    "# Là ngành khoa học kỹ thuật nghiên cứu chế tạo máy thông minh mục đích để học thực hiện các hành vi thông minh \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune GCViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định cấu hình các tham số \n",
    "IMAGE_SIZE = (224 , 224)\n",
    "\n",
    "# Hyperparameter \n",
    "BATCH_SIZE = 32 \n",
    "EPOCHS = 5  \n",
    "\n",
    "# Data class \n",
    "CLASSES = [\n",
    "    \"danelion\",\n",
    "    \"daisy\", \n",
    "    \"tulips\",\n",
    "    \"sùnlowers\",\n",
    "    \"reses\",\n",
    "] \n",
    "\n",
    "# Độ lệch chuẩn và bình quaan tối thiểu mất mát cho hình ảnh \n",
    "MEAN = 255 * np.array([0.485 , 0.456 , 0.406], dtype=\"float32\")\n",
    "STD = 255 * np.array([0.229, 0.224, 0.225], dtype=\"float32\")\n",
    "# XÂY dựng tf.data để cho phép mô hình có khả năng tự đồng tùy chỉnh các thông số dữ liệu \n",
    "# cho phù hợp với thiết bị \n",
    "AUTO = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset: tf.data.Dataset, train: bool , image_size: int = IMAGE_SIZE):\n",
    "    def preprocess(image, label):\n",
    "        # For training , do augmentation \n",
    "        # Kiểm tra xem mô hình có đang trong chế độ huấn luyện không \n",
    "        if train : \n",
    "            # Kiểm tra xem giá trị xác xuất ngẫu nhiên có lớn hơn 0.5 \n",
    "            if tf.random.uniform(shape=[]) > 0.5:\n",
    "                # Nếu thỏa mãn các điều kiện trên thì ta áp dụng các phép tăng cường dữ liệu \n",
    "                image = tf.iamge.flip_left_right(image)\n",
    "            # sau dó ressize lại hình ảnh về kích thước tiêu chuẩn đồng nhất \n",
    "            image = tf.image.resize(image, size=image_size , method=\"bicubic\")\n",
    "            # Biến đổi hình ảnh \n",
    "            image (image - MEAN) / STD # normalization \n",
    "            return image, label\n",
    "\n",
    "    if train : \n",
    "        # TRỘN DỮ LIỆU VỚI KÍCH THƯỚC BATCH_SIZE * 10 \n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
    "    # Áp dụng hàm biến đổi map cho tập dữ liệu\n",
    "    return dataset.map(preprocess, AUTO).batch(BATCH_SIZE).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flower Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset , val_dataset = tfds.load(\n",
    "    \"tf_flowers\", \n",
    "    split = [\"train[:90%]\" ,\"train[:90%]\"],\n",
    "    as_supervised=True , \n",
    "    try_gcs=False , # GCS_path is necessary for tpu \n",
    ")\n",
    "\n",
    "# Tạo2 bộ dữ liệu đào tạo và xác thực sử dụng 90 % dữ liệu đào tạo \n",
    "train_dataset = make_dataset(train_dataset, True)\n",
    "val_dataset = make_dataset(val_dataset, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Build Model for Flower Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re Build the model \n",
    "model = GCViT(**config, num_classes=104)\n",
    "inp = np.array(np.random.uniform(size=(1, 224, 224, 3)))\n",
    "out = model(inp)\n",
    "\n",
    "# Load weight \n",
    "# checkpath file \n",
    "ckpt_path = keras.utils.get_file(ckpt_link.split(\"/\")[-1], ckpt_link)\n",
    "# tối ưu hóa mô hình bằng cách tái sử dụng lại tham số đào tạo trước \n",
    "model.load_weights(ckpt_path, skip_mismatch=True)\n",
    "\n",
    "# Trình biên dịch mô hình cho qúa trình tinh chỉnh \n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, validation_data=val_dataset, epochs=EPOCHS, verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
