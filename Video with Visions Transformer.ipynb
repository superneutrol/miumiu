{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --qq medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io \n",
    "import imageio \n",
    "import medmnist \n",
    "import ipywidgets \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "\n",
    "SEED = 42 \n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "keras.utils.set_random_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "DATASET_NAME = 'orfanmnist3d'\n",
    "BATCH_SIZE = 32  \n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 28 , 28 , 28,1)\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "# OPTIMIZER \n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING \n",
    "EPOCHS = 60 \n",
    "# TUPLE EMBEDDING \n",
    "PATCH_SIZE = ( 8, 8 , 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) **2\n",
    "\n",
    "# VIT ARCHITECTURE \n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128 \n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowload_and_prepare_dataset(data_infor : dict):\n",
    "\n",
    "    data_path = keras.utils.get_file(origin=data_infor['url'], md5_hash=data_infor['MD5'])\n",
    "\n",
    "    with np.load(data_path) as data:\n",
    "        # get video \n",
    "        train_videos = data['train_images']\n",
    "        valid_videos = data['val_images']\n",
    "        test_videos = data['test_images']\n",
    "\n",
    "        # get labels \n",
    "        train_labels = data['train_labels'].flatten()\n",
    "        valid_labels = data['val_labels'].flatten()\n",
    "        test_labels = data['test_labels'].flatten()\n",
    "\n",
    "    return (\n",
    "        (train_videos , train_labels),\n",
    "        (valid_videos , valid_labels),\n",
    "        (test_videos , test_labels),\n",
    "    )\n",
    "\n",
    "# get the metadata of the dataset\n",
    "# lấy siêu dữ liệu của tập dữ liệu \n",
    "infor = medmnist.INFO[DATASET_NAME]\n",
    "\n",
    "# LẤY RA DỮ LIỆU \n",
    "prepare_dataste = dowload_and_prepare_dataset(infor)\n",
    "(train_videos , train_labels) = prepare_dataste[0]\n",
    "(valid_videos , valid_labels) = prepare_dataste[1]\n",
    "(test_videos , test_labels) = prepare_dataste[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function \n",
    "def preprocess(frame: tf.Tensor , label: tf.Tensor):\n",
    "    \"\"\" Xử lý khung hình và phân tích nhãn \"\"\"\n",
    "    # xử lý hình ảnh \n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ], \n",
    "        tf.float32,\n",
    "    )\n",
    "    # Phân tích nhãn \n",
    "    label = tf.cast(label , tf.float32)\n",
    "    return frames , label \n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "        videos: np.ndarray,\n",
    "        labels: np.ndarray, \n",
    "        loader_type: str = \"train\",\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"\"Utility function to prepare the dataloader\n",
    "        Chức năng tiện ích để chuẩn bị cho bộ nạp dữ liệu\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    data_loader = (\n",
    "        dataset.map(preprocess , num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "trainloader = prepare_dataloader(train_videos , train_labels , 'train')\n",
    "validloader = prepare_dataloader(valid_videos, valid_labels, \"valid\")\n",
    "testloader = prepare_dataloader(test_videos, test_labels, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuple Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xây dựng hàm nhúng tuyến tính các video \n",
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self , embed_dim , patch_size , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection_embedding = layers.Conv3D(\n",
    "            filters=embed_dim ,\n",
    "            kernel_size=patch_size, #\n",
    "            strides = patch_size,\n",
    "            padding = 'VALID',\n",
    "        )\n",
    "        # flatetn shape = [batch_size , embed_dim]\n",
    "        self.flatten = layers.Flatten(target_shape=(-1 , embed_dim))\n",
    "    \n",
    "    def call(self, videos):\n",
    "        projection_patches = self.projection_embedding(videos)\n",
    "        flatten_patches = self.flatten(projection_patches)\n",
    "        return flatten_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def buil(self, input_shape):\n",
    "        _, num_tokes, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokes , output_dim=self.embed_dim \n",
    "        )\n",
    "        self.positional = tf.range(start= 0, limit=num_tokes, delta=1)\n",
    "    \n",
    "    def call(self, encoded_tokens):\n",
    "        # encoded the position and add it to the encoded tokens \n",
    "        # mã hóa vị trí và thêm nó vào mã hóa thông báo \n",
    "        encoded_positons = self.position_embedding(self.positional)\n",
    "        encoded_tokens = encoded_tokens + encoded_positons \n",
    "        return encoded_tokens\n",
    "    # trả về mã hóa mã thông báo + mã hóa vị trí của ảnh \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Vision Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vitvit_classifier(\n",
    "        tublet_embed , \n",
    "        positional_encoder, \n",
    "        input_shape = INPUT_SHAPE, \n",
    "        transformer_layers = NUM_LAYERS, \n",
    "        num_heads = NUM_HEADS, \n",
    "        embed_dim = PROJECTION_DIM,\n",
    "        layers_norm_eps = LAYER_NORM_EPS, \n",
    "        num_classes = NUM_CLASSES,\n",
    "):\n",
    "    # get the input layer \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # create patches \n",
    "    patches = tublet_embed(inputs)\n",
    "    # encoded_patches \n",
    "    encoded_patches = positional_encoder(patches)\n",
    "    # create multi layers of the transformer block \n",
    "    for _ in range(transformer_layers):\n",
    "        # layer normlization 1 \n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # add attention layers \n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads , key_dim=embed_dim // num_heads , \n",
    "            dropout=0.1\n",
    "        )(x1 , x1)\n",
    "        # add skip conection \n",
    "        x2 = layers.Add()([attention_output , encoded_patches])\n",
    "        # add layers normalization \n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # add multi layers mlp \n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4 , activation=tf.nn.gele), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(units=embed_dim , activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "        # skip conmection 2 \n",
    "        encoded_patches = layers.Add()([x3 , x2])\n",
    "    \n",
    "    # layers normalization and global average pooling \n",
    "    representation = layers.LayerNormalization(epsilon=layers_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # classifier output \n",
    "    outputs = layers.Dense(units=num_classes , activation='softmax')(representation)\n",
    "\n",
    "    # create keras model \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    # Initialize model \n",
    "    model = create_vitvit_classifier(\n",
    "        tublet_embed=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, \n",
    "            patch_size=PATCH_SIZE,\n",
    "        ),\n",
    "        positional_encoder= PositionalEncoder(\n",
    "            embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "    # compi;e the model with the optimizer , loss funcion \n",
    "    # and the metrics \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss = \"spare_categorical_crossentropy\", \n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5 , name='top-5-accuracy'),\n",
    "        ],\n",
    "    )\n",
    "    # train the model \n",
    "    _ = model.fit(trainloader, epochs=EPOCHS , validation_data=validloader)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
