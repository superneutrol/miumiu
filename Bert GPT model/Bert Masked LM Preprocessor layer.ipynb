{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "keras_nlp.models.BertMaskedLMPreprocessor(\n",
    "    tokenizer, \n",
    "    sequence_length=512,\n",
    "    truncate='round_robin',\n",
    "    mask_selection_length=66,\n",
    "    mask_token_rate=0.8, \n",
    "    mask_selection_rate= 0.15 ,\n",
    "    random_token_rate=0.1,\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.BertMaskedLMPreprocessor.from_preset(\n",
    "    'bert_base_en_uncased'\n",
    ")\n",
    "\n",
    "# Tokenize and mask a sigke sentence. \n",
    "preprocessor('The quick brown fox jumped.')\n",
    "\n",
    "# Tokenize and mask a batch of sigle sentences. \n",
    "preprocessor(['The quick brown fox jumped.', 'Call me Ishmael.'])\n",
    "\n",
    "# Tokenuze and mask a batch of sigle sentences. \n",
    "preprocessor (['The quick brown fox jumped.' , 'Call me Ishmael.'])\n",
    "\n",
    "# Tokenize and mask sentence pairs.\n",
    "# In this case , always convert \n",
    "import tensorflow as tf \n",
    "first = tf.constant(['The quick brown fox jumped.','Call me Ishmael.'])\n",
    "second = tf.constant(['The fox tripped.', 'Oh look a whale.'])\n",
    "preprocessor((first, second))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping with tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.BertMaskedLMPreprocessor.from_preset(\n",
    "    \"bert_base_en_uncased\"\n",
    ")\n",
    "first = tf.constant(['The quick brown fox jumped.','Call me Ishmael.'])\n",
    "second = tf.constant(['The fox tripped.','Oh look, a whale.'])\n",
    "\n",
    "# Map single sentences. \n",
    "ds = tf.data.Dataset.from_tensor_slices(first)\n",
    "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map sentence pairs.\n",
    "ds = tf.data.Dataset.from_tensor_slices((first, second))\n",
    "ds = ds.map(\n",
    "    lambda first , second : preprocessor(x=(first , second)),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
