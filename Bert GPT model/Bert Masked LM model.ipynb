{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp \n",
    "from tensorflow import keras \n",
    "import numpy as  np \n",
    "\n",
    "\n",
    "keras_nlp.models.BertMaskedLM(bacbone , preprocessor=None, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  ['The quick brown fox jumped.','I forgot my home work.']\n",
    "\n",
    "# Pretrained language model \n",
    "masked_lm = keras_nlp.models.BertMaskedLM.from_preset(\n",
    "    'bert_base_en_uncased',\n",
    ")\n",
    "masked_lm.fit(x=features,  batch_size=2)\n",
    "\n",
    "# Re-compile (e.g. , with a new learning rate)\n",
    "masked_lm.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizre = keras.optimizers.Adam(5e-5),\n",
    "    jit_compile = True,\n",
    ")\n",
    "\n",
    "# Acces backbone programtically (e.g., to change 'trainable)\n",
    "masked_lm.backbone.trainable = False\n",
    "# Fit again \n",
    "masked_lm.fit(x=features , batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed interger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessed batch where 0  is the mask token.\n",
    "features = {\n",
    "    'token_ids' : np.array([[1,2,0,4,0,6,7,8]] *2),\n",
    "    'padding_mask' : np.array([[1, 1, 1, 1, 1, 1, 1, 1]] *2),\n",
    "    'mask_positions' : np.array([[2 ,4]] *2),\n",
    "    'segment_ids' : np.array([[0, 0, 0, 0, 0, 0, 0, 0]] *2),\n",
    "}\n",
    "# Labels are the original masked values .\n",
    "labels = [[3,5]] * 2\n",
    "\n",
    "masked_lm = keras_nlp.models.BertMaskedLM.from_preset(\n",
    "    'bert_base_en_uncased',\n",
    "    preprocessor =None,\n",
    ")\n",
    "masked_lm.fit(x =features, y=labels , batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load architecture and weights from preset \n",
    "model = keras_nlp.models.BertMaskedLM.from_preset(\n",
    "    'bert_tiny_en_uncased',\n",
    ")\n",
    "\n",
    "# Load randomly initialized model from preset archotecture\n",
    "model = keras_nlp.models.BertMaskedLM(\n",
    "    \"bert_tiny_en_uncased\",\n",
    "    load_weights=False,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
