{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp \n",
    "keras_nlp.models.BertClassifier(\n",
    "    backbone , num_classes , preprocessor=None , activation=None , dropout=0.1 , **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['The quick brown fox jumped.', 'I forgot my homework.']\n",
    "labels = [0,3]\n",
    "\n",
    "# Pretrained classifier \n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_base_en_uncased\",\n",
    "    num_classes=4, \n",
    ")\n",
    "classifier.fit(x=features , y=labels , batch_size=2)\n",
    "classifier.predict(x =features, batch_size=2)\n",
    "from tensorflow import keras \n",
    "# Re-compile (e.g , with a new learning rate)\n",
    "classifier.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    jit_compile=True,\n",
    ")\n",
    "\n",
    "# Ascces backbone programatically (e.g., to change `trainable`)\n",
    "classifier.backbone.trainable = False\n",
    "# fit again \n",
    "classifier.fit(x=features, y=labels, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed interger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "features = {\n",
    "    'token_ids':  np.ones(shape=(2 ,12), dtype='int32'),\n",
    "    'segment_ids': np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]] *2),\n",
    "    'padding_mask': np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]] *2),\n",
    "}\n",
    "\n",
    "labels = [0, 3]\n",
    "\n",
    "# Pretrained classifier with preprocessing \n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    'bert_base_en_uncased',\n",
    "    num_classes=4,\n",
    "    preprocessor=None,\n",
    ")\n",
    "classifier.fit(x=features, y=labels , batch_size=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom backbone and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['The quick brown fox jumped.', 'I got my homework.']\n",
    "labels = [0,3]\n",
    "\n",
    "vocab = ['[UNK]' ,'[CLS]', '[SEP]', '[PAD]', '[MASK]']\n",
    "vocab += ['The' , 'quick', 'brown', 'fox', 'jumped','.']\n",
    "\n",
    "tokenizer = keras_nlp.models.BertTokenizer(\n",
    "    vocabulary=vocab,\n",
    ")\n",
    "\n",
    "preprocessor = keras_nlp.models.BertPreprocessor(\n",
    "    tokenizer=tokenizer , \n",
    "    sequence_length=128,\n",
    ")\n",
    "\n",
    "backbone = keras_nlp.models.BertBackbone(\n",
    "    vocabulary_size=30552,\n",
    "    num_heads=4 , \n",
    "    num_layers=4, \n",
    "    hidden_dim=256, \n",
    "    intermediate_dim=512 , \n",
    "    max_sequence_length=128,\n",
    ")\n",
    "classifier = keras_nlp.models.BertClassifier(\n",
    "    backbone=backbone , \n",
    "    num_classes=4,\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "classifier.fit(x=features , y=labels, batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
