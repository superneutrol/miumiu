{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "# Download the Dataset Oford iit Pets \n",
    "dataset, info = tfds.load(\"oxford_iiit_pet:3.*.*\", with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import backend \n",
    "\n",
    "# Define parameters\n",
    "image_size = 512 \n",
    "# Mean \n",
    "mean = tf.constant([0.485 , 0.456 , 0.407])\n",
    "# Standard deviation \n",
    "std = tf.constant([0.029 , 0.0224 , 0.225])\n",
    "\n",
    "# Thiết lập phương thức bình thường hóa hình ảnh \n",
    "def normalize(input_image , input_mask):\n",
    "    # Chuyển đổi hình ảnh thành dạng tensor float 32\n",
    "    input_image = tf.image.convert_image_dtype(input_image , tf.float32)\n",
    "    # Thực hiện tiêu chuẩn hình ảnh  = image - mean / maximum(std, backend.epsilon())\n",
    "    input_image = (input_image - mean) / tf.maximum(std, backend.epsilon()) \n",
    "    # Input_mask -= 1\n",
    "    input_mask -= 1 \n",
    "    return input_image , input_image\n",
    "\n",
    "# Thiết lập phương thưcs tải dữ liệu \n",
    "# Với chức năng đặt lại kích thước cho hình ảnh \n",
    "# và kích thước input_mask\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (image_size , image_size))\n",
    "    # Resize input_mask sử dụng phương pháp upsamling với bilinear \n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint[\"segmentation_mask\"],\n",
    "        (image_size, image_size),\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "\n",
    "    # Thực hiện bình thường hóa dữ liệu \n",
    "    # với input_image , input_mask \n",
    "    input_image , input_mask = normalize(input_image, input_mask)\n",
    "    # Chuyển vị hình ảnh để có được tensor với kích thước [channel , h , w]\n",
    "    # vì đây là định dạng trong pytorch sử dụng để lư trữ ảnh \n",
    "    input_image = tf.transpose(input_image , (2 , 0, 1))\n",
    "    # Trả về input _image  và labels dưới dạng từ điển \n",
    "    return {\"pixel_values\": input_image, \"labels\": tf.squeeze(input_mask)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng các tiện ích để chuản bị các đối tượng dữ liệu Dataset bao gồm việc \n",
    "# Tìm nạp trước cho hiệu Suất . \n",
    "# Thay đổi các batch_size cho phù hợp với kích thước của bộ nhớ GPU được sử dụng \n",
    "# để đào tạo \n",
    "auto = tf.data.AUTOTUNE\n",
    "batch_size = 4 \n",
    "\n",
    "# Thiết lập bộ dữ liệu đào tạo \n",
    "train_ds = (\n",
    "    # ĐẦU TIÊN là dữ liệu nguồn\n",
    "    dataset[\"Train\"]\n",
    "    # Lưu chúng vào bộ nhớ cache \n",
    "    .cache()\n",
    "    # Xáo trộn dữ liệu với mộ bộ = batch_size * 4\n",
    "    .shuffle(batch_size * 4)\n",
    "    # sử dụng hàm map để biến đổi dữ liệu \n",
    "    # Với hàm laod_image để chuẩn hóa và biến đổi các hình ảnh \n",
    "    # Lấy song song các bộ dự liệu đặt = auto để tự động điều chỉnh cho \n",
    "    # phù hợp với mô hình \n",
    "    .map(load_image , numm_parallel_calls=auto)\n",
    "    # chia thành các batch mỗi batch = batch_size \n",
    "    .batch(batch_size)\n",
    "    # Tìm nạp trước các bộ dữ liệu để có được trạng thái sẵn sàng cho việc \n",
    "    # sử dụng dữ liệu \n",
    "    .prefetch(auto)\n",
    ")\n",
    "\n",
    "\n",
    "# Thiết lập bộ dữ liệu huấn luyện\n",
    "test_ds = (\n",
    "    # ĐẦU TIÊN là dữ liệu nguồn\n",
    "    dataset[\"test\"]\n",
    "    # sử dụng hàm map để biến đổi dữ liệu \n",
    "    # Với hàm laod_image để chuẩn hóa và biến đổi các hình ảnh \n",
    "    # Lấy song song các bộ dự liệu đặt = auto để tự động điều chỉnh cho \n",
    "    # phù hợp với mô hình \n",
    "    .map(load_image , numm_parallel_calls=auto)\n",
    "    # chia thành các batch mỗi batch = batch_size \n",
    "    .batch(batch_size)\n",
    "    # Tìm nạp trước các bộ dữ liệu để có được trạng thái sẵn sàng cho việc \n",
    "    # sử dụng dữ liệu \n",
    "    .prefetch(auto)\n",
    ")\n",
    "\"\"\"Kiểm tra hình dạng của những hình ảnh đầu vào và phân đoạn đồ thị của chúng\"\"\"\n",
    "train_ds.elements_spec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện trực quan hóa dữ liệu \n",
    "# Xây dựng phương thức hiển thị dữ liệu \n",
    "import matplotlib.pyplot as plt \n",
    "def display (display_list):\n",
    "    # Định cấu hình khung hiển thị inch \n",
    "    plt.figure(figsize=(15 , 15))\n",
    "\n",
    "    # Đặt tiêu đề hiển thị với nhãn là Input Image , True Mask ,Predict Mask \n",
    "    title = [\"Input Image\", \"True Mask\",\"Predicted_mask\"]\n",
    "\n",
    "    # Duyệt qua danh sách các phần tử của display_list \n",
    "    for i in range(len(display_list)):\n",
    "        # Biều dạng subplot với 1 hình ảnh mỗi hàng \n",
    "        plt.subplot(1 , len(display_list) , i+1)\n",
    "        # Add tiêu đề \n",
    "        plt.title(title[i])\n",
    "        # Hiển thị hình ảnh với Image show cần chuyển đổi từ ma trận biểu diễn \n",
    "        # sang hình ảnh với utils.array_to_image \n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        # Bỏ đi các đường kẻ trục \n",
    "        plt.axis(\"off\")\n",
    "    # Hiển thị hàng loạt với plt.show \n",
    "    plt.show()\n",
    "\n",
    "# Duyệt qua 1 danh sách với 2 mẫu từ bộ dữ liệu đào tạo \n",
    "for sample in train_ds.take(2):\n",
    "\n",
    "    # Tạo 2 biến sample image và sample mask là hình ảnh và nhãn tương ứng của ảnh \n",
    "    sample_image , sample_mask = sample[\"pixel_values\"][0], sample[\"labels\"][0]\n",
    "    # Chuyển vị hình ảnh để có dạng image_size , image_size , channels \n",
    "    sample_image = tf.transpose(sample_image, (1 ,2 , 0))\n",
    "    # Thêm 1 chiều vào vị trí cuối cùng cho nhãn\n",
    "    sample_mask = tf.expand_dims(sample_mask , -1)\n",
    "    # Trả về sample và nhãn tương ứng \n",
    "    display([sample_image , sample_mask])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pretrained SegFormer checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFSegformerForSemanticSegmentation \n",
    "\n",
    "# Tạo model_checkpoint \n",
    "model_checkpoint = \"nvidia/mit-b0\"\n",
    "# nhãn cho mô hình là một từ điển với key và values tương ứng \n",
    "id2label = {0: \"outer\", 1: \"inner\", 2: \"border\"}\n",
    "# Duyệt qua danh sách nhãn và lấy ra các bộ tương ứng \n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "num_labels = len(id2label) # lấy ra số lượng nhãn cho mô hình đào tạo trước \n",
    "# Đào tạo trước mô hình đồng thời thêm vào các tham số tương ứng \n",
    "model = TFSegformerForSemanticSegmentation.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo tham số lr \n",
    "lr = 0.00006\n",
    "# Trình tối ưu hóa  = Adam\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# Trìnj biên dịch cho mô hình \n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction callback to monitor training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "\n",
    "# Xây dựng phương thức tạo mặt nạ \n",
    "def create_mask(pred_mask):\n",
    "    # lấy ra chỉ số lớn nhất theo chỉ số hàng \n",
    "    # tức là mỗi vector sẽ lấy ra chỉ số lớn nhất \n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=1)\n",
    "    # Thêm 1 chiều cuối vào tensor_mask  => shape = [bach_size , h , w , -1]\n",
    "    pred_mask = tf.expand_dims(pred_mask, -1)\n",
    "    # Trả về phần từ đầu tiên của tensor tức là mặt nạ của ảnh đầu tiên trong batch \n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "# Xây dựng phương thức hiển thị mặt nạ dự đoán \n",
    "def show_predictions(dataset = None , num=1):\n",
    "    # Kiểm tra xem có tồn tại Dataset \n",
    "    if dataset: \n",
    "        # Duyệt qua danh sách dataset với số lượng num được lấy \n",
    "        for sample in dataset.take(num):\n",
    "            # lấy ra ảnh và mặt nạ \n",
    "            images , masks = sample[\"pixel_values\"] , sample[\"labels\"]\n",
    "            # Thêm chiều cuối cùng cho mask => shape = [batch_size , h , w , 1]\n",
    "            masks = tf.expand_dims(masks , -1)\n",
    "            # Thực hiện dự đoán mask cho hình ảnh \n",
    "            pred_masks = model.predict(images).logits\n",
    "            # Reshape hình ảnh với kich [batch_size ,channel, h , w] -> \n",
    "            # [batch_size , h , w , channels] vì ta chuyển từ thư viện pytorch sang tensorflow \n",
    "            # nên cần thay đổi lại định dạng khác \n",
    "            images = tf.transpose(images , (0 , 2 , 3 , 1))\n",
    "            # Hiển thị hình ảnh và mặt nạ tương ứng của nó với mặt nạ dự đoán \n",
    "            # hiển thị bộ ảnh đầu tiên tronh danh sách \n",
    "            display([images[0], masks[0], create_mask(pred_masks)])\n",
    "    # Trường hợp còn lại\n",
    "    else:\n",
    "        # Thực hiện hiển thị \n",
    "        display(\n",
    "            [\n",
    "                # với hình ảnh và mặt nạ labels\n",
    "                sample_image,\n",
    "                sample_mask,\n",
    "                # Tạo mặt nạ dự đoán \n",
    "                create_mask(model.predict(tf.expand_dims(sample_image, 0))),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# xây dựng phương thưcs callback \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dataset = dataset \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # xóa đầu ra \n",
    "        clear_output(wait=True)\n",
    "        # Thực hiện hiển thị ra các dự đoán từ nguồn ảnh \n",
    "        show_predictions(self.dataset)\n",
    "        print(\"\\nSample Prediction after epoch {}\\n\".format(epoch + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of epochs if the results are not of expected quality.\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[DisplayCallback(test_ds)],\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "show_predictions(test_ds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
